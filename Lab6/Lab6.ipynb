{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DLP Lab6\n",
    "Goal of this lab is to implement a conditional GAN to generate synthetic images according to different conditions\n",
    "1. Shape: cube, sphere, cylinder\n",
    "2. Color: gray, red, blue, green, brown, purple, cyan, yellow\n",
    "\n",
    "#### Implement detail\n",
    "1. Implement training, testing functions, and dataloader\n",
    "2. Choose your conditional GAN architecture\n",
    "3. Design your generator and discriminator\n",
    "4. Choose your loss function\n",
    "5. Output the results based on test.json and new_test.json (will be released before demo)\n",
    "\n",
    "Date: 2020/05/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-24T05:09:14.114186Z",
     "start_time": "2020-05-24T05:09:13.733158Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "import time\n",
    "import gc\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "from torch.utils import data\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.utils import save_image, make_grid\n",
    "import matplotlib.pyplot as plt\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-24T05:09:14.118071Z",
     "start_time": "2020-05-24T05:09:14.115335Z"
    }
   },
   "outputs": [],
   "source": [
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-24T05:09:14.122331Z",
     "start_time": "2020-05-24T05:09:14.119136Z"
    }
   },
   "outputs": [],
   "source": [
    "def show_result(G_losses, D_losses, save = False, path = './img/training_loss.png'):      \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    x = range(len(G_losses))\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.title(\"Training Loss Curve\", fontsize=18)\n",
    "    plt.plot(x, G_losses, label='G_loss')\n",
    "    plt.plot(x, D_losses, label='D_loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    if save:\n",
    "        plt.savefig(path) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-24T05:09:14.126039Z",
     "start_time": "2020-05-24T05:09:14.123238Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_data(mode):\n",
    "    assert mode == 'train' or mode == 'test'\n",
    "    data = json.load(open('./data/'+mode+'.json', 'r'))\n",
    "    if mode == 'train':\n",
    "        data = [i for i in data.items()]\n",
    "    return data\n",
    "\n",
    "def get_objectDic():\n",
    "    return json.load(open('./data/objects.json', 'r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-24T05:09:14.133055Z",
     "start_time": "2020-05-24T05:09:14.126966Z"
    }
   },
   "outputs": [],
   "source": [
    "class GANLoader(data.Dataset):\n",
    "    def __init__(self, mode, image_size=64):\n",
    "        self.mode = mode   \n",
    "        self.data = get_data(mode)\n",
    "        self.obj_dict = get_objectDic()\n",
    "        self.transformation = transforms.Compose([\n",
    "                                  transforms.Resize(image_size),\n",
    "                                  transforms.CenterCrop(image_size),\n",
    "                                  transforms.ToTensor(),\n",
    "                                  transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "                              ])\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        if self.mode == 'train': \n",
    "            img_name = self.data[index][0]\n",
    "            objects = [self.obj_dict[obj] for obj in self.data[index][1]]\n",
    "\n",
    "            # image preprocess\n",
    "            img = np.array(Image.open('./data/iclevr/'+img_name))[...,:-1]\n",
    "            img = self.transformation(Image.fromarray(img))\n",
    "            \n",
    "            # condition embedding - one hot\n",
    "            condition = torch.zeros(24)\n",
    "            condition = torch.tensor([v+1 if i in objects else v for i,v in enumerate(condition)])\n",
    "            \n",
    "            data = (img, condition)\n",
    "        else:\n",
    "            # condition embedding - one hot\n",
    "            objects = [self.obj_dict[obj] for obj in self.data[index]]\n",
    "            condition = torch.zeros(24)\n",
    "            data = torch.tensor([v+1 if i in objects else v for i,v in enumerate(condition)])\n",
    "        \n",
    "        return data     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-24T05:09:14.180782Z",
     "start_time": "2020-05-24T05:09:14.134072Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[[-0.1765, -0.1686, -0.1765,  ..., -0.1765, -0.1843, -0.1765],\n",
      "         [-0.1686, -0.1686, -0.1686,  ..., -0.1765, -0.1843, -0.1843],\n",
      "         [-0.1686, -0.1686, -0.1686,  ..., -0.1843, -0.1843, -0.1765],\n",
      "         ...,\n",
      "         [-0.0431, -0.0431, -0.0353,  ...,  0.1608,  0.1608,  0.1608],\n",
      "         [-0.0431, -0.0353, -0.0353,  ...,  0.1608,  0.1608,  0.1686],\n",
      "         [-0.0431, -0.0353, -0.0353,  ...,  0.1608,  0.1608,  0.1608]],\n",
      "\n",
      "        [[-0.1765, -0.1686, -0.1765,  ..., -0.1765, -0.1843, -0.1765],\n",
      "         [-0.1765, -0.1686, -0.1765,  ..., -0.1765, -0.1843, -0.1843],\n",
      "         [-0.1765, -0.1686, -0.1686,  ..., -0.1843, -0.1843, -0.1843],\n",
      "         ...,\n",
      "         [-0.0510, -0.0510, -0.0431,  ...,  0.1451,  0.1451,  0.1373],\n",
      "         [-0.0510, -0.0431, -0.0431,  ...,  0.1451,  0.1451,  0.1451],\n",
      "         [-0.0510, -0.0510, -0.0431,  ...,  0.1451,  0.1451,  0.1451]],\n",
      "\n",
      "        [[-0.1765, -0.1765, -0.1765,  ..., -0.1765, -0.1843, -0.1765],\n",
      "         [-0.1765, -0.1686, -0.1765,  ..., -0.1765, -0.1843, -0.1843],\n",
      "         [-0.1765, -0.1765, -0.1686,  ..., -0.1843, -0.1843, -0.1843],\n",
      "         ...,\n",
      "         [-0.0667, -0.0588, -0.0588,  ...,  0.1137,  0.1059,  0.1059],\n",
      "         [-0.0588, -0.0588, -0.0588,  ...,  0.1137,  0.1137,  0.1137],\n",
      "         [-0.0667, -0.0588, -0.0588,  ...,  0.1059,  0.1059,  0.1059]]]), tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0.]))\n",
      "tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0.])\n"
     ]
    }
   ],
   "source": [
    "trainset = GANLoader('train', image_size=64)\n",
    "print (trainset[0])\n",
    "testset = GANLoader('test', image_size=64)\n",
    "print (testset[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-24T05:09:14.184821Z",
     "start_time": "2020-05-24T05:09:14.182182Z"
    }
   },
   "outputs": [],
   "source": [
    "# custom weights initialization called\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        nn.init.constant_(m.bias.data, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-24T05:09:14.190611Z",
     "start_time": "2020-05-24T05:09:14.185675Z"
    }
   },
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, latent_size=100, ngf=64):\n",
    "        super(Generator, self).__init__()\n",
    "        self.ngf = ngf\n",
    "        \n",
    "        self.main = nn.Sequential(\n",
    "            # input is Z, going into a convolution\n",
    "            nn.ConvTranspose2d((latent_size+24), ngf * 8, 4, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 8),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf*8) x 4 x 4\n",
    "            nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 4),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf*4) x 8 x 8\n",
    "            nn.ConvTranspose2d( ngf * 4, ngf * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 2),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf*2) x 16 x 16\n",
    "            nn.ConvTranspose2d( ngf * 2, ngf, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf) x 32 x 32\n",
    "            nn.ConvTranspose2d( ngf, 3, 4, 2, 1, bias=False),\n",
    "            nn.Tanh()\n",
    "            # state size. 3 x 64 x 64\n",
    "        )\n",
    "\n",
    "    def forward(self, input, condition):\n",
    "        input = torch.cat((input, condition.view(input.size(0), -1, 1, 1)), 1)\n",
    "        return self.main(input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-24T05:09:14.197007Z",
     "start_time": "2020-05-24T05:09:14.191507Z"
    }
   },
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, ndf=64):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.ndf = ndf\n",
    "        self.linear = nn.Linear(24, ndf*ndf)\n",
    "        \n",
    "        self.main = nn.Sequential(\n",
    "            # input is 4 x 64 x 64\n",
    "            nn.Conv2d(4, ndf, 4, 2, 1, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf) x 32 x 32\n",
    "            nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 2),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf*2) x 16 x 16\n",
    "            nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 4),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf*4) x 8 x 8\n",
    "            nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf*8) x 4 x 4\n",
    "            nn.Conv2d(ndf * 8, 1, 4, 1, 0, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, input, condition):\n",
    "        condition = self.linear(condition).view(input.size(0), 1, self.ndf, self.ndf)\n",
    "        input = torch.cat((input, condition), 1)\n",
    "        return self.main(input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-24T05:09:14.200431Z",
     "start_time": "2020-05-24T05:09:14.197849Z"
    }
   },
   "outputs": [],
   "source": [
    "def learning_schedule(epoch):\n",
    "    G_dict={400:1e-4, 300:2e-4, 200:3e-4, 100:4e-4, 0:5e-4}\n",
    "    D_dict={400:2e-6, 300:4e-6, 200:6e-6, 100:8e-6, 0:1e-5}\n",
    "    for k in G_dict.keys():\n",
    "        if epoch >= k:\n",
    "            return G_dict[k], D_dict[k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-24T05:09:14.210568Z",
     "start_time": "2020-05-24T05:09:14.201244Z"
    }
   },
   "outputs": [],
   "source": [
    "def training(G, D, image_size, latent_size, learning_rate, batch_size, num_epochs):\n",
    "    start = time.time()\n",
    "    real_label = 1\n",
    "    fake_label = 0\n",
    "    \n",
    "    # recording list\n",
    "    G_losses = []\n",
    "    D_losses = []\n",
    "    \n",
    "    # init dataloader \n",
    "    trainset = GANLoader('train', image_size=64)\n",
    "    trainloader = data.DataLoader(trainset, batch_size, num_workers=2, shuffle=True)\n",
    "\n",
    "    # init criterion & optimizer\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizerD = optim.Adam(D.parameters(), lr=learning_rate, betas=(2e-4, 0.999))\n",
    "    optimizerG = optim.Adam(G.parameters(), lr=learning_rate, betas=(2e-4, 0.999))\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        # learning rate decay\n",
    "        optimizerG.param_groups[0]['lr'] = learning_schedule(epoch)[0]\n",
    "        optimizerD.param_groups[0]['lr'] = learning_schedule(epoch)[1]\n",
    "        \n",
    "        for idx, datas in enumerate(trainloader):\n",
    "            b_size = datas[0].size(0)\n",
    "            img = datas[0].to(device)\n",
    "            condition = datas[1].to(device)\n",
    "            \n",
    "            #------part1 - train discriminator: maximize log(D(x)) + log(1 - D(G(z)))-----#\n",
    "            ## all real batch\n",
    "            D.zero_grad()\n",
    "            label = torch.full((b_size,), real_label, device=device)\n",
    "            output = D(img, condition).view(-1)\n",
    "            \n",
    "            errD_real = criterion(output, label)\n",
    "            errD_real.backward()\n",
    "            D_x = output.mean().item() \n",
    "\n",
    "            ## all fake batch\n",
    "            noise = torch.randn(b_size, latent_size, 1, 1, device=device)\n",
    "            fake = G(noise, condition)\n",
    "            label.fill_(fake_label)\n",
    "            \n",
    "            output = D(fake.detach(), condition).view(-1)\n",
    "            \n",
    "            errD_fake = criterion(output, label)\n",
    "            errD_fake.backward()\n",
    "            D_G_z1 = output.mean().item()\n",
    "            \n",
    "            errD = errD_real + errD_fake\n",
    "            \n",
    "            # Update D\n",
    "            optimizerD.step()\n",
    "            \n",
    "            #------part2 - train generator: maximize log(D(G(z)))-----#\n",
    "            G.zero_grad()\n",
    "            label.fill_(real_label)\n",
    "            output = D(fake, condition).view(-1)\n",
    "            \n",
    "            errG = criterion(output, label)\n",
    "            errG.backward()\n",
    "            D_G_z2 = output.mean().item()\n",
    "            \n",
    "            # Update G\n",
    "            optimizerG.step()\n",
    "\n",
    "        acc,_ = testing(G, D, latent_size, batch_size)\n",
    "        if acc>0.5556 :\n",
    "            print (\"Model save...\")\n",
    "            torch.save(G, \"./models/G_{:.4f}.ckpt\".format(acc))\n",
    "            torch.save(D, \"./models/D_{:.4f}.ckpt\".format(acc))\n",
    "            \n",
    "        if epoch % 1 == 0:\n",
    "            print('%s (%d %d%%) Accuracy: %.4f Loss_D: %.4f Loss_G: %.4f D(x): %.4f D(G(z)): %.4f / %.4f'\n",
    "                          % (timeSince(start, (epoch+1)/num_epochs), epoch, epoch/num_epochs * 100, \n",
    "                              acc, errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))\n",
    "        \n",
    "        G_losses.append(errG.item())\n",
    "        D_losses.append(errD.item())\n",
    "        collected = gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "    return G_losses, D_losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-24T05:09:14.215412Z",
     "start_time": "2020-05-24T05:09:14.211523Z"
    }
   },
   "outputs": [],
   "source": [
    "# Output generate images - https://pytorch.org/docs/stable/torchvision/utils.html\n",
    "def testing(G, D, latent_size, batch_size):\n",
    "    from evaluator import evaluation_model\n",
    "    E = evaluation_model()\n",
    "    \n",
    "    img_list = []\n",
    "    acc_list = []\n",
    "    \n",
    "    # init dataloader \n",
    "    testset = GANLoader('test')\n",
    "    testloader = data.DataLoader(testset, batch_size, num_workers=2)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for condition in testloader:\n",
    "            condition = condition.to(device)\n",
    "            b_size = condition.size(0)\n",
    "            noise = torch.randn(b_size, latent_size, 1, 1, device=device)\n",
    "            fake = G(noise, condition).detach()\n",
    "            \n",
    "            acc_list.append(E.eval(fake, condition))\n",
    "            img_list.append(make_grid(fake, nrow=8, padding=2, normalize=True).cpu())\n",
    "\n",
    "    return sum(acc_list)/len(acc_list), img_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-05-24T05:09:13.734Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0m 34s (- 402m 27s) (0 0%) Accuracy: 0.0833 Loss_D: 8.6278 Loss_G: 0.0027 D(x): 0.5001 D(G(z)): 0.9992 / 0.9973\n",
      "1m 8s (- 399m 27s) (1 0%) Accuracy: 0.1389 Loss_D: 7.0874 Loss_G: 0.0251 D(x): 0.1381 D(G(z)): 0.9893 / 0.9753\n",
      "1m 42s (- 397m 2s) (2 0%) Accuracy: 0.0972 Loss_D: 5.5774 Loss_G: 0.0538 D(x): 0.3851 D(G(z)): 0.9836 / 0.9480\n",
      "2m 16s (- 395m 35s) (3 0%) Accuracy: 0.0833 Loss_D: 5.1737 Loss_G: 0.1270 D(x): 0.1982 D(G(z)): 0.9367 / 0.8812\n",
      "2m 50s (- 394m 9s) (4 0%) Accuracy: 0.0694 Loss_D: 5.8533 Loss_G: 0.1341 D(x): 0.0535 D(G(z)): 0.9145 / 0.8749\n",
      "3m 24s (- 393m 35s) (5 0%) Accuracy: 0.0972 Loss_D: 4.1786 Loss_G: 0.1251 D(x): 0.2854 D(G(z)): 0.9255 / 0.8826\n",
      "3m 57s (- 392m 40s) (6 0%) Accuracy: 0.0833 Loss_D: 3.7001 Loss_G: 0.2355 D(x): 0.3335 D(G(z)): 0.8887 / 0.7910\n",
      "4m 31s (- 391m 38s) (7 1%) Accuracy: 0.0556 Loss_D: 0.2959 Loss_G: 8.4622 D(x): 0.8038 D(G(z)): 0.0002 / 0.0002\n",
      "5m 5s (- 390m 56s) (8 1%) Accuracy: 0.0833 Loss_D: 3.1466 Loss_G: 0.3978 D(x): 0.2327 D(G(z)): 0.7141 / 0.6725\n",
      "5m 39s (- 390m 17s) (9 1%) Accuracy: 0.0972 Loss_D: 2.9328 Loss_G: 0.3823 D(x): 0.2443 D(G(z)): 0.7154 / 0.6825\n",
      "6m 13s (- 390m 13s) (10 1%) Accuracy: 0.0972 Loss_D: 2.4485 Loss_G: 0.4890 D(x): 0.3906 D(G(z)): 0.6840 / 0.6137\n",
      "6m 47s (- 389m 28s) (11 1%) Accuracy: 0.0972 Loss_D: 2.3296 Loss_G: 0.4660 D(x): 0.3317 D(G(z)): 0.6540 / 0.6277\n",
      "7m 21s (- 388m 43s) (12 1%) Accuracy: 0.0833 Loss_D: 2.0950 Loss_G: 0.5954 D(x): 0.3739 D(G(z)): 0.5777 / 0.5516\n",
      "7m 57s (- 389m 56s) (13 1%) Accuracy: 0.0833 Loss_D: 1.9222 Loss_G: 0.5994 D(x): 0.4292 D(G(z)): 0.5800 / 0.5493\n",
      "8m 32s (- 390m 5s) (14 2%) Accuracy: 0.0833 Loss_D: 1.4607 Loss_G: 0.8787 D(x): 0.5259 D(G(z)): 0.5027 / 0.4159\n",
      "9m 7s (- 390m 0s) (15 2%) Accuracy: 0.1111 Loss_D: 1.2957 Loss_G: 0.9143 D(x): 0.5306 D(G(z)): 0.4378 / 0.4014\n",
      "9m 42s (- 389m 57s) (16 2%) Accuracy: 0.0972 Loss_D: 1.3930 Loss_G: 0.6664 D(x): 0.6628 D(G(z)): 0.5821 / 0.5226\n",
      "10m 17s (- 389m 47s) (17 2%) Accuracy: 0.0556 Loss_D: 2.1348 Loss_G: 0.4092 D(x): 0.3792 D(G(z)): 0.6746 / 0.6655\n",
      "10m 52s (- 389m 30s) (18 2%) Accuracy: 0.1111 Loss_D: 1.9528 Loss_G: 0.4978 D(x): 0.3999 D(G(z)): 0.6207 / 0.6091\n",
      "11m 27s (- 389m 18s) (19 2%) Accuracy: 0.1667 Loss_D: 1.8617 Loss_G: 0.5816 D(x): 0.3960 D(G(z)): 0.5679 / 0.5593\n",
      "12m 1s (- 388m 58s) (20 2%) Accuracy: 0.1250 Loss_D: 1.8197 Loss_G: 0.5639 D(x): 0.4384 D(G(z)): 0.6148 / 0.5705\n",
      "12m 36s (- 388m 36s) (21 3%) Accuracy: 0.1250 Loss_D: 1.7966 Loss_G: 0.5890 D(x): 0.3965 D(G(z)): 0.5605 / 0.5554\n",
      "13m 11s (- 388m 24s) (22 3%) Accuracy: 0.0833 Loss_D: 1.6350 Loss_G: 0.6195 D(x): 0.4405 D(G(z)): 0.5507 / 0.5387\n",
      "13m 46s (- 388m 5s) (23 3%) Accuracy: 0.0833 Loss_D: 1.7093 Loss_G: 0.6041 D(x): 0.4215 D(G(z)): 0.5547 / 0.5482\n",
      "14m 21s (- 387m 42s) (24 3%) Accuracy: 0.0694 Loss_D: 1.9397 Loss_G: 0.4730 D(x): 0.4659 D(G(z)): 0.6533 / 0.6310\n",
      "14m 56s (- 387m 17s) (25 3%) Accuracy: 0.0694 Loss_D: 1.6519 Loss_G: 0.6157 D(x): 0.4366 D(G(z)): 0.5436 / 0.5405\n",
      "15m 31s (- 386m 53s) (26 3%) Accuracy: 0.1250 Loss_D: 1.3647 Loss_G: 0.7857 D(x): 0.5137 D(G(z)): 0.4656 / 0.4620\n",
      "16m 6s (- 386m 30s) (27 3%) Accuracy: 0.0694 Loss_D: 1.5347 Loss_G: 0.6334 D(x): 0.4873 D(G(z)): 0.5474 / 0.5319\n",
      "16m 41s (- 386m 2s) (28 4%) Accuracy: 0.0694 Loss_D: 1.5519 Loss_G: 0.6609 D(x): 0.4662 D(G(z)): 0.5313 / 0.5169\n",
      "17m 15s (- 385m 35s) (29 4%) Accuracy: 0.0833 Loss_D: 1.4817 Loss_G: 0.6824 D(x): 0.4944 D(G(z)): 0.5216 / 0.5063\n",
      "17m 50s (- 385m 9s) (30 4%) Accuracy: 0.0972 Loss_D: 1.4496 Loss_G: 0.7122 D(x): 0.4862 D(G(z)): 0.4974 / 0.4932\n",
      "18m 25s (- 384m 41s) (31 4%) Accuracy: 0.0972 Loss_D: 1.3966 Loss_G: 0.7180 D(x): 0.5074 D(G(z)): 0.4984 / 0.4892\n",
      "19m 0s (- 384m 16s) (32 4%) Accuracy: 0.0556 Loss_D: 1.4386 Loss_G: 0.7388 D(x): 0.4873 D(G(z)): 0.4928 / 0.4781\n",
      "19m 35s (- 383m 46s) (33 4%) Accuracy: 0.0833 Loss_D: 1.4444 Loss_G: 0.7227 D(x): 0.4919 D(G(z)): 0.4998 / 0.4904\n",
      "20m 10s (- 383m 16s) (34 4%) Accuracy: 0.1111 Loss_D: 1.3660 Loss_G: 0.7760 D(x): 0.5082 D(G(z)): 0.4867 / 0.4612\n",
      "20m 45s (- 382m 46s) (35 5%) Accuracy: 0.1111 Loss_D: 1.5153 Loss_G: 0.6943 D(x): 0.4937 D(G(z)): 0.5351 / 0.5013\n",
      "21m 20s (- 382m 18s) (36 5%) Accuracy: 0.0972 Loss_D: 1.4330 Loss_G: 0.7181 D(x): 0.4989 D(G(z)): 0.5056 / 0.4886\n",
      "21m 55s (- 381m 50s) (37 5%) Accuracy: 0.0972 Loss_D: 1.3797 Loss_G: 0.7425 D(x): 0.4981 D(G(z)): 0.4751 / 0.4775\n",
      "22m 30s (- 381m 24s) (38 5%) Accuracy: 0.0694 Loss_D: 1.3252 Loss_G: 0.8174 D(x): 0.4979 D(G(z)): 0.4539 / 0.4421\n",
      "23m 5s (- 380m 54s) (39 5%) Accuracy: 0.0556 Loss_D: 1.3027 Loss_G: 0.7787 D(x): 0.5225 D(G(z)): 0.4708 / 0.4619\n",
      "23m 39s (- 380m 23s) (40 5%) Accuracy: 0.1111 Loss_D: 1.3955 Loss_G: 0.6815 D(x): 0.5124 D(G(z)): 0.5127 / 0.5065\n",
      "24m 14s (- 379m 53s) (41 5%) Accuracy: 0.0972 Loss_D: 1.3062 Loss_G: 0.8039 D(x): 0.5218 D(G(z)): 0.4713 / 0.4489\n",
      "24m 49s (- 379m 21s) (42 6%) Accuracy: 0.0833 Loss_D: 1.3107 Loss_G: 0.7856 D(x): 0.5202 D(G(z)): 0.4693 / 0.4612\n",
      "25m 24s (- 378m 51s) (43 6%) Accuracy: 0.1250 Loss_D: 1.4273 Loss_G: 0.7250 D(x): 0.5062 D(G(z)): 0.5087 / 0.4872\n",
      "25m 59s (- 378m 20s) (44 6%) Accuracy: 0.1111 Loss_D: 1.3803 Loss_G: 0.7800 D(x): 0.5174 D(G(z)): 0.5013 / 0.4607\n",
      "26m 34s (- 377m 49s) (45 6%) Accuracy: 0.0694 Loss_D: 1.4543 Loss_G: 0.6933 D(x): 0.4815 D(G(z)): 0.5080 / 0.5008\n",
      "27m 9s (- 377m 16s) (46 6%) Accuracy: 0.1250 Loss_D: 1.2366 Loss_G: 0.8710 D(x): 0.5720 D(G(z)): 0.4821 / 0.4206\n",
      "27m 44s (- 376m 51s) (47 6%) Accuracy: 0.1111 Loss_D: 1.3414 Loss_G: 0.7579 D(x): 0.5361 D(G(z)): 0.5064 / 0.4728\n",
      "28m 19s (- 376m 21s) (48 6%) Accuracy: 0.1111 Loss_D: 1.3885 Loss_G: 0.7243 D(x): 0.5159 D(G(z)): 0.5082 / 0.4856\n",
      "28m 55s (- 375m 55s) (49 7%) Accuracy: 0.1111 Loss_D: 1.3416 Loss_G: 0.7462 D(x): 0.5132 D(G(z)): 0.4856 / 0.4757\n",
      "29m 29s (- 375m 21s) (50 7%) Accuracy: 0.1667 Loss_D: 1.3558 Loss_G: 0.7806 D(x): 0.5090 D(G(z)): 0.4848 / 0.4592\n",
      "30m 3s (- 374m 35s) (51 7%) Accuracy: 0.1111 Loss_D: 1.2818 Loss_G: 0.7930 D(x): 0.5231 D(G(z)): 0.4577 / 0.4549\n",
      "30m 37s (- 373m 51s) (52 7%) Accuracy: 0.1250 Loss_D: 1.3958 Loss_G: 0.7338 D(x): 0.5039 D(G(z)): 0.5005 / 0.4814\n",
      "31m 11s (- 373m 5s) (53 7%) Accuracy: 0.0972 Loss_D: 1.3745 Loss_G: 0.7271 D(x): 0.4828 D(G(z)): 0.4688 / 0.4854\n",
      "31m 45s (- 372m 24s) (54 7%) Accuracy: 0.0833 Loss_D: 1.4357 Loss_G: 0.7112 D(x): 0.5089 D(G(z)): 0.5255 / 0.4918\n",
      "32m 19s (- 371m 41s) (55 7%) Accuracy: 0.1250 Loss_D: 1.4187 Loss_G: 0.7522 D(x): 0.5083 D(G(z)): 0.5197 / 0.4726\n",
      "32m 53s (- 370m 58s) (56 8%) Accuracy: 0.1111 Loss_D: 1.4061 Loss_G: 0.7937 D(x): 0.5482 D(G(z)): 0.5482 / 0.4545\n",
      "33m 26s (- 370m 14s) (57 8%) Accuracy: 0.1111 Loss_D: 1.3547 Loss_G: 0.8239 D(x): 0.5380 D(G(z)): 0.5138 / 0.4397\n",
      "34m 0s (- 369m 32s) (58 8%) Accuracy: 0.1111 Loss_D: 1.3780 Loss_G: 0.7517 D(x): 0.5310 D(G(z)): 0.5213 / 0.4725\n",
      "34m 34s (- 368m 49s) (59 8%) Accuracy: 0.1250 Loss_D: 1.4048 Loss_G: 0.6258 D(x): 0.4405 D(G(z)): 0.4379 / 0.5365\n",
      "35m 8s (- 368m 6s) (60 8%) Accuracy: 0.1667 Loss_D: 1.3922 Loss_G: 0.7453 D(x): 0.4996 D(G(z)): 0.5002 / 0.4753\n",
      "35m 42s (- 367m 25s) (61 8%) Accuracy: 0.0833 Loss_D: 1.3512 Loss_G: 0.6972 D(x): 0.4961 D(G(z)): 0.4759 / 0.4994\n",
      "36m 16s (- 366m 43s) (62 8%) Accuracy: 0.1389 Loss_D: 1.4133 Loss_G: 0.7763 D(x): 0.5089 D(G(z)): 0.5199 / 0.4606\n",
      "36m 50s (- 366m 4s) (63 9%) Accuracy: 0.1528 Loss_D: 1.3938 Loss_G: 0.7027 D(x): 0.4959 D(G(z)): 0.4981 / 0.4959\n",
      "37m 24s (- 365m 25s) (64 9%) Accuracy: 0.1111 Loss_D: 1.4247 Loss_G: 0.6409 D(x): 0.4669 D(G(z)): 0.4832 / 0.5274\n",
      "37m 58s (- 364m 51s) (65 9%) Accuracy: 0.1250 Loss_D: 1.4372 Loss_G: 0.5876 D(x): 0.4394 D(G(z)): 0.4576 / 0.5565\n",
      "38m 33s (- 364m 16s) (66 9%) Accuracy: 0.2083 Loss_D: 1.4185 Loss_G: 0.7423 D(x): 0.5172 D(G(z)): 0.5308 / 0.4767\n",
      "39m 7s (- 363m 36s) (67 9%) Accuracy: 0.1250 Loss_D: 1.4055 Loss_G: 0.6579 D(x): 0.4714 D(G(z)): 0.4787 / 0.5185\n",
      "39m 41s (- 362m 57s) (68 9%) Accuracy: 0.1806 Loss_D: 1.3784 Loss_G: 0.7357 D(x): 0.5152 D(G(z)): 0.5099 / 0.4800\n",
      "40m 16s (- 362m 25s) (69 9%) Accuracy: 0.1389 Loss_D: 1.4085 Loss_G: 0.6408 D(x): 0.4733 D(G(z)): 0.4822 / 0.5275\n",
      "40m 51s (- 361m 57s) (70 10%) Accuracy: 0.1667 Loss_D: 1.4076 Loss_G: 0.7161 D(x): 0.5162 D(G(z)): 0.5249 / 0.4890\n",
      "41m 26s (- 361m 28s) (71 10%) Accuracy: 0.0833 Loss_D: 1.4004 Loss_G: 0.6539 D(x): 0.4698 D(G(z)): 0.4741 / 0.5204\n",
      "42m 1s (- 360m 57s) (72 10%) Accuracy: 0.1667 Loss_D: 1.4099 Loss_G: 0.7514 D(x): 0.5154 D(G(z)): 0.5256 / 0.4722\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42m 36s (- 360m 28s) (73 10%) Accuracy: 0.1250 Loss_D: 1.3946 Loss_G: 0.6753 D(x): 0.4914 D(G(z)): 0.4947 / 0.5095\n",
      "43m 11s (- 359m 56s) (74 10%) Accuracy: 0.2222 Loss_D: 1.4039 Loss_G: 0.6910 D(x): 0.4859 D(G(z)): 0.4931 / 0.5016\n",
      "43m 46s (- 359m 23s) (75 10%) Accuracy: 0.0833 Loss_D: 1.3869 Loss_G: 0.7132 D(x): 0.5014 D(G(z)): 0.5005 / 0.4909\n",
      "44m 20s (- 358m 48s) (76 10%) Accuracy: 0.1806 Loss_D: 1.3997 Loss_G: 0.7828 D(x): 0.5320 D(G(z)): 0.5352 / 0.4577\n",
      "44m 54s (- 358m 8s) (77 11%) Accuracy: 0.1389 Loss_D: 1.3981 Loss_G: 0.6475 D(x): 0.4567 D(G(z)): 0.4582 / 0.5239\n",
      "45m 28s (- 357m 26s) (78 11%) Accuracy: 0.0972 Loss_D: 1.3947 Loss_G: 0.7361 D(x): 0.5231 D(G(z)): 0.5255 / 0.4793\n",
      "46m 2s (- 356m 51s) (79 11%) Accuracy: 0.1250 Loss_D: 1.3905 Loss_G: 0.6364 D(x): 0.4707 D(G(z)): 0.4703 / 0.5297\n",
      "46m 37s (- 356m 17s) (80 11%) Accuracy: 0.1528 Loss_D: 1.3810 Loss_G: 0.6606 D(x): 0.4686 D(G(z)): 0.4631 / 0.5169\n",
      "47m 11s (- 355m 36s) (81 11%) Accuracy: 0.1250 Loss_D: 1.3910 Loss_G: 0.6264 D(x): 0.4661 D(G(z)): 0.4654 / 0.5351\n",
      "47m 45s (- 355m 0s) (82 11%) Accuracy: 0.1250 Loss_D: 1.3783 Loss_G: 0.6921 D(x): 0.4903 D(G(z)): 0.4852 / 0.5010\n",
      "48m 19s (- 354m 21s) (83 11%) Accuracy: 0.1389 Loss_D: 1.4000 Loss_G: 0.8062 D(x): 0.5357 D(G(z)): 0.5391 / 0.4469\n",
      "48m 53s (- 353m 42s) (84 12%) Accuracy: 0.1528 Loss_D: 1.3873 Loss_G: 0.8770 D(x): 0.5659 D(G(z)): 0.5580 / 0.4169\n",
      "49m 27s (- 353m 6s) (85 12%) Accuracy: 0.1250 Loss_D: 1.3823 Loss_G: 0.6262 D(x): 0.4413 D(G(z)): 0.4304 / 0.5356\n",
      "50m 1s (- 352m 28s) (86 12%) Accuracy: 0.1667 Loss_D: 1.3782 Loss_G: 0.6971 D(x): 0.4991 D(G(z)): 0.4943 / 0.4993\n",
      "50m 36s (- 351m 59s) (87 12%) Accuracy: 0.1111 Loss_D: 1.3897 Loss_G: 0.6976 D(x): 0.4887 D(G(z)): 0.4892 / 0.4982\n",
      "51m 11s (- 351m 25s) (88 12%) Accuracy: 0.1806 Loss_D: 1.4109 Loss_G: 0.8871 D(x): 0.5747 D(G(z)): 0.5748 / 0.4126\n",
      "51m 46s (- 350m 52s) (89 12%) Accuracy: 0.1389 Loss_D: 1.3802 Loss_G: 0.6554 D(x): 0.4764 D(G(z)): 0.4712 / 0.5196\n",
      "52m 21s (- 350m 20s) (90 12%) Accuracy: 0.2083 Loss_D: 1.3912 Loss_G: 0.6167 D(x): 0.4426 D(G(z)): 0.4367 / 0.5405\n",
      "52m 55s (- 349m 46s) (91 13%) Accuracy: 0.1944 Loss_D: 1.3952 Loss_G: 0.6401 D(x): 0.4591 D(G(z)): 0.4593 / 0.5276\n",
      "53m 29s (- 349m 8s) (92 13%) Accuracy: 0.1806 Loss_D: 1.3821 Loss_G: 0.6409 D(x): 0.4668 D(G(z)): 0.4613 / 0.5273\n",
      "54m 3s (- 348m 30s) (93 13%) Accuracy: 0.2500 Loss_D: 1.3944 Loss_G: 0.6967 D(x): 0.5031 D(G(z)): 0.5065 / 0.4985\n",
      "54m 37s (- 347m 53s) (94 13%) Accuracy: 0.2778 Loss_D: 1.3777 Loss_G: 0.7300 D(x): 0.5118 D(G(z)): 0.5066 / 0.4824\n",
      "55m 11s (- 347m 16s) (95 13%) Accuracy: 0.2222 Loss_D: 1.3799 Loss_G: 0.6908 D(x): 0.4889 D(G(z)): 0.4848 / 0.5015\n",
      "55m 46s (- 346m 43s) (96 13%) Accuracy: 0.2361 Loss_D: 1.3860 Loss_G: 0.7249 D(x): 0.5054 D(G(z)): 0.5046 / 0.4846\n",
      "56m 21s (- 346m 12s) (97 13%) Accuracy: 0.1667 Loss_D: 1.3815 Loss_G: 0.7180 D(x): 0.4954 D(G(z)): 0.4921 / 0.4883\n",
      "56m 56s (- 345m 41s) (98 14%) Accuracy: 0.2083 Loss_D: 1.3974 Loss_G: 0.6494 D(x): 0.4788 D(G(z)): 0.4824 / 0.5229\n",
      "57m 30s (- 345m 5s) (99 14%) Accuracy: 0.1806 Loss_D: 1.3933 Loss_G: 0.6116 D(x): 0.4499 D(G(z)): 0.4473 / 0.5435\n",
      "58m 6s (- 344m 39s) (100 14%) Accuracy: 0.2917 Loss_D: 1.3803 Loss_G: 0.7351 D(x): 0.5009 D(G(z)): 0.4972 / 0.4797\n",
      "58m 42s (- 344m 11s) (101 14%) Accuracy: 0.2917 Loss_D: 1.3848 Loss_G: 0.7146 D(x): 0.5046 D(G(z)): 0.5030 / 0.4898\n",
      "59m 17s (- 343m 39s) (102 14%) Accuracy: 0.2361 Loss_D: 1.3821 Loss_G: 0.7608 D(x): 0.5145 D(G(z)): 0.5114 / 0.4676\n",
      "59m 52s (- 343m 8s) (103 14%) Accuracy: 0.2500 Loss_D: 1.4016 Loss_G: 0.6295 D(x): 0.4657 D(G(z)): 0.4706 / 0.5334\n",
      "60m 27s (- 342m 37s) (104 14%) Accuracy: 0.2778 Loss_D: 1.4059 Loss_G: 0.7314 D(x): 0.5111 D(G(z)): 0.5196 / 0.4816\n",
      "61m 2s (- 342m 4s) (105 15%) Accuracy: 0.2639 Loss_D: 1.3897 Loss_G: 0.6928 D(x): 0.4895 D(G(z)): 0.4904 / 0.5007\n",
      "61m 36s (- 341m 28s) (106 15%) Accuracy: 0.1667 Loss_D: 1.4034 Loss_G: 0.7714 D(x): 0.5272 D(G(z)): 0.5329 / 0.4628\n"
     ]
    }
   ],
   "source": [
    "image_size = 64 \n",
    "latent_size = 100\n",
    "learning_rate = 0.0002\n",
    "batch_size = 128\n",
    "num_epochs = 700\n",
    "\n",
    "\n",
    "G = Generator(latent_size=100, ngf=64).to(device)\n",
    "G.apply(weights_init)\n",
    "D = Discriminator(ndf=64).to(device)\n",
    "D.apply(weights_init)\n",
    "G_losses, D_losses = training(G, D, image_size, latent_size, learning_rate, batch_size, num_epochs)\n",
    "show_result(G_losses, D_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-05-24T05:09:13.735Z"
    }
   },
   "outputs": [],
   "source": [
    "D = torch.load('./models/D_0.5556.ckpt')\n",
    "G = torch.load('./models/G_0.5556.ckpt')\n",
    "acc, imgs = testing(G, D, latent_size, batch_size)\n",
    "fig = plt.figure(figsize=(15,15))\n",
    "plt.imshow(np.transpose(imgs[0],(1,2,0)))\n",
    "print (\"Accuracy: %.4f\"%(acc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
