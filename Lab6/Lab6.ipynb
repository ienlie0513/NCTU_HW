{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DLP Lab6\n",
    "Goal of this lab is to implement a conditional GAN to generate synthetic images according to different conditions\n",
    "1. Shape: cube, sphere, cylinder\n",
    "2. Color: gray, red, blue, green, brown, purple, cyan, yellow\n",
    "\n",
    "#### Implement detail\n",
    "1. Implement training, testing functions, and dataloader\n",
    "2. Choose your conditional GAN architecture\n",
    "3. Design your generator and discriminator\n",
    "4. Choose your loss function\n",
    "5. Output the results based on test.json and new_test.json (will be released before demo)\n",
    "\n",
    "Date: 2020/05/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-23T09:59:15.795075Z",
     "start_time": "2020-05-23T09:59:15.414772Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "import time\n",
    "import math\n",
    "import zipfile\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "from torch.utils import data\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "import matplotlib.pyplot as plt\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-23T09:59:15.799083Z",
     "start_time": "2020-05-23T09:59:15.796214Z"
    }
   },
   "outputs": [],
   "source": [
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-23T09:59:15.804050Z",
     "start_time": "2020-05-23T09:59:15.800101Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_data(mode):\n",
    "    assert mode == 'train' or mode == 'test'\n",
    "    data = json.load(open('./data/'+mode+'.json', 'r'))\n",
    "    if mode == 'train':\n",
    "        data = [i for i in data.items()]\n",
    "    return data\n",
    "\n",
    "def get_objectDic():\n",
    "    return json.load(open('./data/objects.json', 'r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-23T09:59:15.811217Z",
     "start_time": "2020-05-23T09:59:15.804976Z"
    }
   },
   "outputs": [],
   "source": [
    "class GANLoader(data.Dataset):\n",
    "    def __init__(self, mode, image_size):\n",
    "        self.mode = mode   \n",
    "        self.data = get_data(mode)\n",
    "        self.obj_dict = get_objectDic()\n",
    "        self.transformation = transforms.Compose([\n",
    "                                  transforms.Resize(image_size),\n",
    "                                  transforms.CenterCrop(image_size),\n",
    "                                  transforms.ToTensor(),\n",
    "                                  transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "                              ])\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        if self.mode == 'train': \n",
    "            img_name = self.data[index][0]\n",
    "            objects = [self.obj_dict[obj] for obj in self.data[index][1]]\n",
    "\n",
    "            # image preprocess\n",
    "            zippedImgs = zipfile.ZipFile('./data/iclevr.zip')\n",
    "            img = np.array(Image.open(zippedImgs.open(img_name)))[...,:-1]\n",
    "            img = self.transformation(Image.fromarray(img))\n",
    "            \n",
    "            # condition embedding - one hot\n",
    "            condition = torch.zeros(24)\n",
    "            condition = torch.tensor([v+1 if i in objects else v for i,v in enumerate(condition)])\n",
    "            \n",
    "            data = (img, condition)\n",
    "        else:\n",
    "            # condition embedding - one hot\n",
    "            objects = [self.obj_dict[obj] for obj in self.data[index]]\n",
    "            condition = torch.zeros(24)\n",
    "            data = torch.tensor([v+1 if i in objects else v for i,v in enumerate(condition)])\n",
    "        \n",
    "        return data     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-23T09:59:15.954576Z",
     "start_time": "2020-05-23T09:59:15.812109Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[[-0.1765, -0.1686, -0.1765,  ..., -0.1765, -0.1843, -0.1765],\n",
      "         [-0.1686, -0.1686, -0.1686,  ..., -0.1765, -0.1843, -0.1843],\n",
      "         [-0.1686, -0.1686, -0.1686,  ..., -0.1843, -0.1843, -0.1765],\n",
      "         ...,\n",
      "         [-0.0431, -0.0431, -0.0353,  ...,  0.1608,  0.1608,  0.1608],\n",
      "         [-0.0431, -0.0353, -0.0353,  ...,  0.1608,  0.1608,  0.1686],\n",
      "         [-0.0431, -0.0353, -0.0353,  ...,  0.1608,  0.1608,  0.1608]],\n",
      "\n",
      "        [[-0.1765, -0.1686, -0.1765,  ..., -0.1765, -0.1843, -0.1765],\n",
      "         [-0.1765, -0.1686, -0.1765,  ..., -0.1765, -0.1843, -0.1843],\n",
      "         [-0.1765, -0.1686, -0.1686,  ..., -0.1843, -0.1843, -0.1843],\n",
      "         ...,\n",
      "         [-0.0510, -0.0510, -0.0431,  ...,  0.1451,  0.1451,  0.1373],\n",
      "         [-0.0510, -0.0431, -0.0431,  ...,  0.1451,  0.1451,  0.1451],\n",
      "         [-0.0510, -0.0510, -0.0431,  ...,  0.1451,  0.1451,  0.1451]],\n",
      "\n",
      "        [[-0.1765, -0.1765, -0.1765,  ..., -0.1765, -0.1843, -0.1765],\n",
      "         [-0.1765, -0.1686, -0.1765,  ..., -0.1765, -0.1843, -0.1843],\n",
      "         [-0.1765, -0.1765, -0.1686,  ..., -0.1843, -0.1843, -0.1843],\n",
      "         ...,\n",
      "         [-0.0667, -0.0588, -0.0588,  ...,  0.1137,  0.1059,  0.1059],\n",
      "         [-0.0588, -0.0588, -0.0588,  ...,  0.1137,  0.1137,  0.1137],\n",
      "         [-0.0667, -0.0588, -0.0588,  ...,  0.1059,  0.1059,  0.1059]]]), tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0.]))\n",
      "tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0.])\n"
     ]
    }
   ],
   "source": [
    "trainset = GANLoader('train', image_size=64)\n",
    "print (trainset[0])\n",
    "testset = GANLoader('test', image_size=64)\n",
    "print (testset[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-23T09:59:15.958522Z",
     "start_time": "2020-05-23T09:59:15.955532Z"
    }
   },
   "outputs": [],
   "source": [
    "# custom weights initialization called\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        nn.init.constant_(m.bias.data, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-23T09:59:15.965127Z",
     "start_time": "2020-05-23T09:59:15.959841Z"
    }
   },
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, latent_size=100, ngf=64):\n",
    "        super(Generator, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            # input is Z, going into a convolution\n",
    "            nn.ConvTranspose2d(latent_size, ngf * 8, 4, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 8),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf*8) x 4 x 4\n",
    "            nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 4),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf*4) x 8 x 8\n",
    "            nn.ConvTranspose2d( ngf * 4, ngf * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 2),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf*2) x 16 x 16\n",
    "            nn.ConvTranspose2d( ngf * 2, ngf, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf) x 32 x 32\n",
    "            nn.ConvTranspose2d( ngf, 3, 4, 2, 1, bias=False),\n",
    "            nn.Tanh()\n",
    "            # state size. 3 x 64 x 64\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.main(input)\n",
    "    \n",
    "    def weights_init(self):\n",
    "        for m in self._modules:\n",
    "            normal_init(self._modules[m], mean, std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-23T09:59:15.971226Z",
     "start_time": "2020-05-23T09:59:15.966282Z"
    }
   },
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, ndf=64):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            # input is 3 x 64 x 64\n",
    "            nn.Conv2d(3, ndf, 4, 2, 1, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf) x 32 x 32\n",
    "            nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 2),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf*2) x 16 x 16\n",
    "            nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 4),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf*4) x 8 x 8\n",
    "            nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf*8) x 4 x 4\n",
    "            nn.Conv2d(ndf * 8, 1, 4, 1, 0, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.main(input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-23T09:59:15.982586Z",
     "start_time": "2020-05-23T09:59:15.972350Z"
    }
   },
   "outputs": [],
   "source": [
    "def training(G, D, image_size, latent_size, learning_rate, batch_size, num_epochs):\n",
    "    start = time.time()\n",
    "    real_label = 1\n",
    "    fake_label = 0\n",
    "    \n",
    "    # recording list\n",
    "    img_list = []\n",
    "    G_losses = []\n",
    "    D_losses = []\n",
    "    \n",
    "    # init dataloader \n",
    "    trainset = GANLoader('train', image_size=64)\n",
    "    trainloader = data.DataLoader(trainset, batch_size, shuffle=True)\n",
    "\n",
    "    # init criterion & optimizer\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizerD = optim.Adam(D.parameters(), lr=learning_rate, betas=(2e-4, 0.999))\n",
    "    optimizerG = optim.Adam(G.parameters(), lr=learning_rate, betas=(2e-4, 0.999))\n",
    "    \n",
    "    # init noise\n",
    "    fixed_noise = torch.randn(64, latent_size, 1, 1, device=device)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        for idx, datas in enumerate(trainloader):\n",
    "            b_size = datas[0].size(0)\n",
    "            #------part1 - train discriminator: maximize log(D(x)) + log(1 - D(G(z)))-----#\n",
    "            ## all real batch\n",
    "            D.zero_grad()\n",
    "            \n",
    "            img = datas[0].to(device)\n",
    "            condition = datas[1].to(device)\n",
    "            \n",
    "#             # cat condition\n",
    "#             condition = torch.cat((condition, condition, condition), 0)\n",
    "#             img = torch.cat((img, condition), 1)\n",
    "            \n",
    "            label = torch.full((b_size,), real_label, device=device)\n",
    "            \n",
    "            output = D(img).view(-1)\n",
    "            \n",
    "            errD_real = criterion(output, label)\n",
    "            errD_real.backward()\n",
    "            D_x = output.mean().item() \n",
    "\n",
    "            ## all fake batch\n",
    "            noise = torch.randn(b_size, latent_size, 1, 1, device=device)\n",
    "            fake = G(noise)\n",
    "            label.fill_(fake_label)\n",
    "            \n",
    "            output = D(fake.detach()).view(-1)\n",
    "            \n",
    "            errD_fake = criterion(output, label)\n",
    "            errD_fake.backward()\n",
    "            D_G_z1 = output.mean().item()\n",
    "            \n",
    "            errD = errD_real + errD_fake\n",
    "            \n",
    "            # Update D\n",
    "            optimizerD.step()\n",
    "            \n",
    "            #------part2 - train generator: maximize log(D(G(z)))-----#\n",
    "            G.zero_grad()\n",
    "            label.fill_(real_label)\n",
    "            output = D(fake).view(-1)\n",
    "            \n",
    "            errG = criterion(output, label)\n",
    "            errG.backward()\n",
    "            D_G_z2 = output.mean().item()\n",
    "            \n",
    "            # Update G\n",
    "            optimizerG.step()\n",
    "\n",
    "            if idx % 10 == 0:\n",
    "                print('%s [%2d/%d][%3d/%d]\\tLoss_D: %.4f\\tLoss_G: %.4f\\tD(x): %.4f\\tD(G(z)): %.4f / %.4f'\n",
    "                          % (timeSince(start, epoch+1 / num_epochs), epoch, num_epochs, idx, len(trainloader),\n",
    "                             errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))\n",
    "\n",
    "        G_losses.append(errG.item())\n",
    "        D_losses.append(errD.item())\n",
    "\n",
    "        with torch.no_grad():\n",
    "            fake = G(fixed_noise).detach().cpu()\n",
    "        img_list.append(vutils.make_grid(fake, padding=2, normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-23T09:59:15.985370Z",
     "start_time": "2020-05-23T09:59:15.983596Z"
    }
   },
   "outputs": [],
   "source": [
    "# Output generate images - https://pytorch.org/docs/stable/torchvision/utils.html\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-05-23T09:59:15.421Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0m 13s (- 2m 0s) [ 0/10][  0/141]\tLoss_D: 1.9867\tLoss_G: 2.3837\tD(x): 0.2635\tD(G(z)): 0.3132 / 0.1397\n",
      "2m 21s (- 21m 11s) [ 0/10][ 10/141]\tLoss_D: 0.2229\tLoss_G: 5.7078\tD(x): 0.8919\tD(G(z)): 0.0023 / 0.0059\n",
      "4m 31s (- 40m 47s) [ 0/10][ 20/141]\tLoss_D: 0.0222\tLoss_G: 5.7202\tD(x): 0.9938\tD(G(z)): 0.0152 / 0.0055\n",
      "6m 41s (- 60m 9s) [ 0/10][ 30/141]\tLoss_D: 0.0937\tLoss_G: 12.7969\tD(x): 0.9880\tD(G(z)): 0.0748 / 0.0000\n",
      "8m 50s (- 79m 33s) [ 0/10][ 40/141]\tLoss_D: 0.0093\tLoss_G: 8.1744\tD(x): 0.9921\tD(G(z)): 0.0004 / 0.0004\n",
      "11m 3s (- 99m 34s) [ 0/10][ 50/141]\tLoss_D: 0.0700\tLoss_G: 18.5132\tD(x): 0.9976\tD(G(z)): 0.0630 / 0.0000\n",
      "13m 15s (- 119m 17s) [ 0/10][ 60/141]\tLoss_D: 0.0629\tLoss_G: 13.0088\tD(x): 0.9553\tD(G(z)): 0.0000 / 0.0000\n",
      "15m 26s (- 138m 58s) [ 0/10][ 70/141]\tLoss_D: 0.4217\tLoss_G: 44.9765\tD(x): 0.9951\tD(G(z)): 0.2675 / 0.0000\n",
      "17m 38s (- 158m 44s) [ 0/10][ 80/141]\tLoss_D: 0.0021\tLoss_G: 13.5453\tD(x): 0.9980\tD(G(z)): 0.0000 / 0.0000\n",
      "19m 47s (- 178m 9s) [ 0/10][ 90/141]\tLoss_D: 3.0572\tLoss_G: 40.6144\tD(x): 0.9965\tD(G(z)): 0.9073 / 0.0000\n",
      "21m 58s (- 197m 45s) [ 0/10][100/141]\tLoss_D: 0.0397\tLoss_G: 9.7153\tD(x): 0.9833\tD(G(z)): 0.0001 / 0.0001\n",
      "24m 9s (- 217m 26s) [ 0/10][110/141]\tLoss_D: 0.4217\tLoss_G: 25.2282\tD(x): 0.9842\tD(G(z)): 0.2647 / 0.0000\n",
      "26m 21s (- 237m 14s) [ 0/10][120/141]\tLoss_D: 2.6047\tLoss_G: 39.2364\tD(x): 0.9989\tD(G(z)): 0.8360 / 0.0000\n",
      "28m 32s (- 256m 54s) [ 0/10][130/141]\tLoss_D: 0.0079\tLoss_G: 15.0795\tD(x): 0.9926\tD(G(z)): 0.0000 / 0.0000\n",
      "30m 40s (- 276m 4s) [ 0/10][140/141]\tLoss_D: 2.3395\tLoss_G: 5.9881\tD(x): 0.4482\tD(G(z)): 0.0000 / 0.0034\n",
      "30m 53s (- -3m 11s) [ 1/10][  0/141]\tLoss_D: 0.1372\tLoss_G: 7.5440\tD(x): 0.9881\tD(G(z)): 0.1084 / 0.0010\n"
     ]
    }
   ],
   "source": [
    "image_size = 64 \n",
    "latent_size = 100\n",
    "learning_rate = 0.0002\n",
    "batch_size = 128\n",
    "num_epochs = 10\n",
    "\n",
    "\n",
    "G = Generator(latent_size=100, ngf=64).to(device)\n",
    "G.apply(weights_init)\n",
    "D = Discriminator(ndf=64).to(device)\n",
    "D.apply(weights_init)\n",
    "training(G, D, image_size, latent_size, learning_rate, batch_size, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-23T08:51:34.250318Z",
     "start_time": "2020-05-23T08:20:05.316Z"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
