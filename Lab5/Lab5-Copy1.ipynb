{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DLP Lab5\n",
    "Goal of this lab is to to implement a conditional seq2seq VAE for English tense conversion\n",
    "1. Tense conversion: ‘access’ to ‘accessing’, or ‘accessed’ to ‘accesses’\n",
    "2. Generative model: Gaussian noise + tense -> access, accesses, accessing, accessed\n",
    "\n",
    "#### Requirment\n",
    "1. Implement a conditional seq2seq VAE.\n",
    "    * Modify encoder, decoder, and training functions\n",
    "    * Implement evaluation function, dataloader, and reparameterization trick.\n",
    "2. Plot and **compare** the CrossEntropy loss, KL loss and BLEU-4 score of testing data curves during training with different settings of your model\n",
    "    * Teacher forcing ratio\n",
    "    * KL annealing schedules (two methods)\n",
    "3. Output the conversion results between tenses (from tense A to tense B)\n",
    "4. Output the results generated by a Gaussian noise with 4 tenses.\n",
    "\n",
    "#### Implement detail\n",
    "1. Use LSTM\n",
    "2. Log variance\n",
    "3. Condition (tense)\n",
    "    * Simply concatenate to the hidden_0 and z\n",
    "    * Embed your condition to high dimensional space (or simply use one-hot)\n",
    "4. KL lost annealing\n",
    "    * Monotonic\n",
    "    * Cyclical\n",
    "5. Adopt BLEU-4 score function in NLTK (average 10 testing scores)\n",
    "6. Adopt Gaussian_score() to compute the generation score\n",
    "    * Random sample 100 noise to generate 100 words with 4 different tenses(totally 400 words)\n",
    "    * 4 words should exactly match the training data\n",
    "\n",
    "#### Hyper parameters\n",
    "* LSTM hidden size: 256 or 512\n",
    "* Latent size: 32\n",
    "* Condition embedding size: 8\n",
    "* Teacher forcing ratio: 0~1 (>0.5) (??? \n",
    "* KL weight: 0~1 (???\n",
    "* Learning rate: 0.05\n",
    "* Optimizer: SGD\n",
    "* Loss function: torch.nn.CrossEntropyLoss()\n",
    "\n",
    "Date: 2020/05/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-11T03:14:19.758548Z",
     "start_time": "2020-05-11T03:14:18.251912Z"
    }
   },
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "import time\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils import data\n",
    "import matplotlib.pyplot as plt\n",
    "plt.switch_backend('agg')\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from os import system\n",
    "from nltk.translate.bleu_score import SmoothingFunction, sentence_bleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-11T03:14:19.844862Z",
     "start_time": "2020-05-11T03:14:19.759754Z"
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "#----------Hyper Parameters----------#\n",
    "hidden_size = 256\n",
    "laten_size = 32\n",
    "condition_size = 8\n",
    "#The number of vocabulary\n",
    "vocab_size = 30\n",
    "teacher_forcing_ratio = 1.0\n",
    "empty_input_ratio = 0.1\n",
    "KLD_weight = 0.0\n",
    "learning_rate = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-11T03:14:19.850264Z",
     "start_time": "2020-05-11T03:14:19.846672Z"
    }
   },
   "outputs": [],
   "source": [
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %2ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetch data\n",
    "* train.txt: Each training pair includes 4 words: simple present(sp), third person(tp), present progressive(pg), simple past(p)\n",
    "* test.txt: Each training pair includes 2 words with different combination of tenses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-11T03:14:19.870317Z",
     "start_time": "2020-05-11T03:14:19.851475Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>abandon</td>\n",
       "      <td>abandons</td>\n",
       "      <td>abandoning</td>\n",
       "      <td>abandoned</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>abet</td>\n",
       "      <td>abets</td>\n",
       "      <td>abetting</td>\n",
       "      <td>abetted</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>abdicate</td>\n",
       "      <td>abdicates</td>\n",
       "      <td>abdicating</td>\n",
       "      <td>abdicated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>abduct</td>\n",
       "      <td>abducts</td>\n",
       "      <td>abducting</td>\n",
       "      <td>abducted</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>abound</td>\n",
       "      <td>abounds</td>\n",
       "      <td>abounding</td>\n",
       "      <td>abounded</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1222</th>\n",
       "      <td>exhort</td>\n",
       "      <td>exhorts</td>\n",
       "      <td>exhorting</td>\n",
       "      <td>exhorted</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1223</th>\n",
       "      <td>exhilarate</td>\n",
       "      <td>exhilarates</td>\n",
       "      <td>exhilarating</td>\n",
       "      <td>exhilarated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1224</th>\n",
       "      <td>exculpate</td>\n",
       "      <td>exculpates</td>\n",
       "      <td>exculpating</td>\n",
       "      <td>exculpated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1225</th>\n",
       "      <td>exasperate</td>\n",
       "      <td>exasperates</td>\n",
       "      <td>exasperating</td>\n",
       "      <td>exasperated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1226</th>\n",
       "      <td>exacerbate</td>\n",
       "      <td>exacerbates</td>\n",
       "      <td>exacerbating</td>\n",
       "      <td>exacerbated</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1227 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0            1             2            3\n",
       "0        abandon     abandons    abandoning    abandoned\n",
       "1           abet        abets      abetting      abetted\n",
       "2       abdicate    abdicates    abdicating    abdicated\n",
       "3         abduct      abducts     abducting     abducted\n",
       "4         abound      abounds     abounding     abounded\n",
       "...          ...          ...           ...          ...\n",
       "1222      exhort      exhorts     exhorting     exhorted\n",
       "1223  exhilarate  exhilarates  exhilarating  exhilarated\n",
       "1224   exculpate   exculpates   exculpating   exculpated\n",
       "1225  exasperate  exasperates  exasperating  exasperated\n",
       "1226  exacerbate  exacerbates  exacerbating  exacerbated\n",
       "\n",
       "[1227 rows x 4 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def getData(mode):\n",
    "    assert mode == 'train' or mode == 'test'\n",
    "    if mode == 'train':\n",
    "        data = pd.read_csv('./data/'+mode+'.txt', delimiter=' ', header=None)\n",
    "    else:\n",
    "        data = []\n",
    "        with open('./data/test.txt','r') as fp:\n",
    "            for line in fp:\n",
    "                word = line.split(' ')\n",
    "                word[1] = word[1].strip('\\n')\n",
    "                data.extend([word])\n",
    "    return data\n",
    "\n",
    "getData(\"train\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-11T03:14:19.877301Z",
     "start_time": "2020-05-11T03:14:19.871334Z"
    }
   },
   "outputs": [],
   "source": [
    "class Vocabuary():\n",
    "    def __init__(self):\n",
    "        self.word2index = {'SOS': 0, 'EOS': 1, 'PAD': 2, 'UNK': 3}\n",
    "        self.index2word = {0: 'SOS', 1: 'EOS', 2: 'PAD', 3: 'UNK'}\n",
    "        self.n_words = 4\n",
    "        self.max_length = 0\n",
    "        self.build_vocab(getData('train'))\n",
    "        \n",
    "\n",
    "    # input the training data and build vocabulary\n",
    "    def build_vocab(self, corpus):        \n",
    "        for idx in range(corpus.shape[0]):\n",
    "            for word in corpus.iloc[idx,:]:\n",
    "                if len(word) > self.max_length:\n",
    "                    self.max_length = len(word)\n",
    "                    \n",
    "                for char in word:\n",
    "                    if char not in self.word2index:\n",
    "                        self.word2index[char] = self.n_words\n",
    "                        self.index2word[self.n_words] = char\n",
    "                        self.n_words += 1                      \n",
    "                    \n",
    "    # convert word in indices\n",
    "    def word2indices(self, word, add_eos=False, add_sos=False):\n",
    "        indices = [self.word2index[char] if char in self.word2index else 3 for char in word]\n",
    "\n",
    "        if add_sos:\n",
    "            indices.insert(0, 0)\n",
    "        if add_eos:\n",
    "            indices.append(1)\n",
    "            \n",
    "        # padding input of same target into same length\n",
    "        indices.extend([2]*(self.max_length-len(word)))\n",
    "            \n",
    "        return np.array(indices)\n",
    "    \n",
    "    # convert indices to word\n",
    "    def indices2word(self, indices):\n",
    "        word = [self.index2word[idx] for idx in indices if idx > 2 ]\n",
    "        return ''.join(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-11T03:14:20.015686Z",
     "start_time": "2020-05-11T03:14:19.878296Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12 29 14 15 20 17  4 13 12  7  2  2  2  2  2]\n",
      "exculpated\n"
     ]
    }
   ],
   "source": [
    "v = Vocabuary()\n",
    "t = \"exculpated\"\n",
    "idx = v.word2indices(t)\n",
    "print(idx)\n",
    "t = v.indices2word(idx)\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-11T03:14:20.021557Z",
     "start_time": "2020-05-11T03:14:20.017240Z"
    }
   },
   "outputs": [],
   "source": [
    "class TenseLoader(data.Dataset):\n",
    "    def __init__(self, mode, vocab):\n",
    "        self.mode = mode   \n",
    "        self.data = getData(self.mode)\n",
    "        self.vocab = vocab\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        if self.mode == 'train':\n",
    "            data_tensor = []\n",
    "            for word in self.data.iloc[index,:]:\n",
    "                data_tensor.append(self.vocab.word2indices(word))\n",
    "        else:\n",
    "            condition = [[\"sp\", \"p\"], [\"sp\", \"pg\"], [\"sp\", \"tp\"], [\"sp\", \"tp\"], [\"p\", \"tp\"], \n",
    "                        [\"sp\", \"pg\"], [\"p\", \"sp\"], [\"pg\", \"sp\"], [\"pg\", \"p\"], [\"pg\", \"tp\"]]\n",
    "            input_tensor = self.vocab.word2indices(self.data[index][0])\n",
    "            target_tensor = self.vocab.word2indices(self.data[index][0])\n",
    "        return torch.tensor(data_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-11T03:14:20.031229Z",
     "start_time": "2020-05-11T03:14:20.022575Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 4,  5,  4,  6,  7,  8,  6,  2,  2,  2,  2,  2,  2,  2,  2],\n",
       "        [ 4,  5,  4,  6,  7,  8,  6,  9,  2,  2,  2,  2,  2,  2,  2],\n",
       "        [ 4,  5,  4,  6,  7,  8,  6, 10,  6, 11,  2,  2,  2,  2,  2],\n",
       "        [ 4,  5,  4,  6,  7,  8,  6, 12,  7,  2,  2,  2,  2,  2,  2]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainset = TenseLoader('train', v)\n",
    "trainset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Show reslut\n",
    "* Crossentropy loss curve\n",
    "* KL loss curve\n",
    "* BLEU-4 score curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-11T03:14:20.034951Z",
     "start_time": "2020-05-11T03:14:20.032142Z"
    }
   },
   "outputs": [],
   "source": [
    "def show_result(score, c_loss, kl_loss):  \n",
    "    label = [\"BLEU Score\", \"Crossentropy Loss\", \"KL Loss\"]\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    plt.ylabel(\"Loss & Score\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.title(\"Training Curve\", fontsize=18)\n",
    "    plt.plot(score, label=\"BLEU Score\")\n",
    "    plt.plot(c_loss, label=\"Crossentropy Loss\")\n",
    "    plt.plot(kl_loss, label=\"KL Loss\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Condition\n",
    "concatenate the condition part with the initial hidden part \n",
    "* nn.Embedding\n",
    "* One-hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-11T03:14:20.079747Z",
     "start_time": "2020-05-11T03:14:20.035757Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[ 0.7214, -1.1775,  1.0754, -0.4868, -0.6969, -0.8959, -2.2780,  1.5519],\n",
       "         [ 0.7214, -1.1775,  1.0754, -0.4868, -0.6969, -0.8959, -2.2780,  1.5519],\n",
       "         [ 0.7214, -1.1775,  1.0754, -0.4868, -0.6969, -0.8959, -2.2780,  1.5519],\n",
       "         [ 0.7214, -1.1775,  1.0754, -0.4868, -0.6969, -0.8959, -2.2780,  1.5519],\n",
       "         [ 0.7214, -1.1775,  1.0754, -0.4868, -0.6969, -0.8959, -2.2780,  1.5519],\n",
       "         [ 0.7214, -1.1775,  1.0754, -0.4868, -0.6969, -0.8959, -2.2780,  1.5519],\n",
       "         [ 0.7214, -1.1775,  1.0754, -0.4868, -0.6969, -0.8959, -2.2780,  1.5519],\n",
       "         [ 0.7214, -1.1775,  1.0754, -0.4868, -0.6969, -0.8959, -2.2780,  1.5519],\n",
       "         [ 0.7214, -1.1775,  1.0754, -0.4868, -0.6969, -0.8959, -2.2780,  1.5519],\n",
       "         [ 0.7214, -1.1775,  1.0754, -0.4868, -0.6969, -0.8959, -2.2780,  1.5519],\n",
       "         [ 0.7214, -1.1775,  1.0754, -0.4868, -0.6969, -0.8959, -2.2780,  1.5519],\n",
       "         [ 0.7214, -1.1775,  1.0754, -0.4868, -0.6969, -0.8959, -2.2780,  1.5519],\n",
       "         [ 0.7214, -1.1775,  1.0754, -0.4868, -0.6969, -0.8959, -2.2780,  1.5519],\n",
       "         [ 0.7214, -1.1775,  1.0754, -0.4868, -0.6969, -0.8959, -2.2780,  1.5519],\n",
       "         [ 0.7214, -1.1775,  1.0754, -0.4868, -0.6969, -0.8959, -2.2780,  1.5519],\n",
       "         [ 0.7214, -1.1775,  1.0754, -0.4868, -0.6969, -0.8959, -2.2780,  1.5519],\n",
       "         [ 0.7214, -1.1775,  1.0754, -0.4868, -0.6969, -0.8959, -2.2780,  1.5519],\n",
       "         [ 0.7214, -1.1775,  1.0754, -0.4868, -0.6969, -0.8959, -2.2780,  1.5519],\n",
       "         [ 0.7214, -1.1775,  1.0754, -0.4868, -0.6969, -0.8959, -2.2780,  1.5519],\n",
       "         [ 0.7214, -1.1775,  1.0754, -0.4868, -0.6969, -0.8959, -2.2780,  1.5519],\n",
       "         [ 0.7214, -1.1775,  1.0754, -0.4868, -0.6969, -0.8959, -2.2780,  1.5519],\n",
       "         [ 0.7214, -1.1775,  1.0754, -0.4868, -0.6969, -0.8959, -2.2780,  1.5519],\n",
       "         [ 0.7214, -1.1775,  1.0754, -0.4868, -0.6969, -0.8959, -2.2780,  1.5519],\n",
       "         [ 0.7214, -1.1775,  1.0754, -0.4868, -0.6969, -0.8959, -2.2780,  1.5519],\n",
       "         [ 0.7214, -1.1775,  1.0754, -0.4868, -0.6969, -0.8959, -2.2780,  1.5519],\n",
       "         [ 0.7214, -1.1775,  1.0754, -0.4868, -0.6969, -0.8959, -2.2780,  1.5519],\n",
       "         [ 0.7214, -1.1775,  1.0754, -0.4868, -0.6969, -0.8959, -2.2780,  1.5519],\n",
       "         [ 0.7214, -1.1775,  1.0754, -0.4868, -0.6969, -0.8959, -2.2780,  1.5519],\n",
       "         [ 0.7214, -1.1775,  1.0754, -0.4868, -0.6969, -0.8959, -2.2780,  1.5519],\n",
       "         [ 0.7214, -1.1775,  1.0754, -0.4868, -0.6969, -0.8959, -2.2780,  1.5519],\n",
       "         [ 0.7214, -1.1775,  1.0754, -0.4868, -0.6969, -0.8959, -2.2780,  1.5519],\n",
       "         [ 0.7214, -1.1775,  1.0754, -0.4868, -0.6969, -0.8959, -2.2780,  1.5519]],\n",
       "        grad_fn=<CatBackward>),\n",
       " tensor([[-0.2515, -1.0392, -0.3315,  1.2395, -0.8113,  1.1466,  0.8694,  1.4193],\n",
       "         [-0.2515, -1.0392, -0.3315,  1.2395, -0.8113,  1.1466,  0.8694,  1.4193],\n",
       "         [-0.2515, -1.0392, -0.3315,  1.2395, -0.8113,  1.1466,  0.8694,  1.4193],\n",
       "         [-0.2515, -1.0392, -0.3315,  1.2395, -0.8113,  1.1466,  0.8694,  1.4193],\n",
       "         [-0.2515, -1.0392, -0.3315,  1.2395, -0.8113,  1.1466,  0.8694,  1.4193],\n",
       "         [-0.2515, -1.0392, -0.3315,  1.2395, -0.8113,  1.1466,  0.8694,  1.4193],\n",
       "         [-0.2515, -1.0392, -0.3315,  1.2395, -0.8113,  1.1466,  0.8694,  1.4193],\n",
       "         [-0.2515, -1.0392, -0.3315,  1.2395, -0.8113,  1.1466,  0.8694,  1.4193],\n",
       "         [-0.2515, -1.0392, -0.3315,  1.2395, -0.8113,  1.1466,  0.8694,  1.4193],\n",
       "         [-0.2515, -1.0392, -0.3315,  1.2395, -0.8113,  1.1466,  0.8694,  1.4193],\n",
       "         [-0.2515, -1.0392, -0.3315,  1.2395, -0.8113,  1.1466,  0.8694,  1.4193],\n",
       "         [-0.2515, -1.0392, -0.3315,  1.2395, -0.8113,  1.1466,  0.8694,  1.4193],\n",
       "         [-0.2515, -1.0392, -0.3315,  1.2395, -0.8113,  1.1466,  0.8694,  1.4193],\n",
       "         [-0.2515, -1.0392, -0.3315,  1.2395, -0.8113,  1.1466,  0.8694,  1.4193],\n",
       "         [-0.2515, -1.0392, -0.3315,  1.2395, -0.8113,  1.1466,  0.8694,  1.4193],\n",
       "         [-0.2515, -1.0392, -0.3315,  1.2395, -0.8113,  1.1466,  0.8694,  1.4193],\n",
       "         [-0.2515, -1.0392, -0.3315,  1.2395, -0.8113,  1.1466,  0.8694,  1.4193],\n",
       "         [-0.2515, -1.0392, -0.3315,  1.2395, -0.8113,  1.1466,  0.8694,  1.4193],\n",
       "         [-0.2515, -1.0392, -0.3315,  1.2395, -0.8113,  1.1466,  0.8694,  1.4193],\n",
       "         [-0.2515, -1.0392, -0.3315,  1.2395, -0.8113,  1.1466,  0.8694,  1.4193],\n",
       "         [-0.2515, -1.0392, -0.3315,  1.2395, -0.8113,  1.1466,  0.8694,  1.4193],\n",
       "         [-0.2515, -1.0392, -0.3315,  1.2395, -0.8113,  1.1466,  0.8694,  1.4193],\n",
       "         [-0.2515, -1.0392, -0.3315,  1.2395, -0.8113,  1.1466,  0.8694,  1.4193],\n",
       "         [-0.2515, -1.0392, -0.3315,  1.2395, -0.8113,  1.1466,  0.8694,  1.4193],\n",
       "         [-0.2515, -1.0392, -0.3315,  1.2395, -0.8113,  1.1466,  0.8694,  1.4193],\n",
       "         [-0.2515, -1.0392, -0.3315,  1.2395, -0.8113,  1.1466,  0.8694,  1.4193],\n",
       "         [-0.2515, -1.0392, -0.3315,  1.2395, -0.8113,  1.1466,  0.8694,  1.4193],\n",
       "         [-0.2515, -1.0392, -0.3315,  1.2395, -0.8113,  1.1466,  0.8694,  1.4193],\n",
       "         [-0.2515, -1.0392, -0.3315,  1.2395, -0.8113,  1.1466,  0.8694,  1.4193],\n",
       "         [-0.2515, -1.0392, -0.3315,  1.2395, -0.8113,  1.1466,  0.8694,  1.4193],\n",
       "         [-0.2515, -1.0392, -0.3315,  1.2395, -0.8113,  1.1466,  0.8694,  1.4193],\n",
       "         [-0.2515, -1.0392, -0.3315,  1.2395, -0.8113,  1.1466,  0.8694,  1.4193]],\n",
       "        grad_fn=<CatBackward>),\n",
       " tensor([[ 0.0107,  0.0736,  0.9130,  1.0870, -1.5547,  2.0408,  0.6073,  0.2628],\n",
       "         [ 0.0107,  0.0736,  0.9130,  1.0870, -1.5547,  2.0408,  0.6073,  0.2628],\n",
       "         [ 0.0107,  0.0736,  0.9130,  1.0870, -1.5547,  2.0408,  0.6073,  0.2628],\n",
       "         [ 0.0107,  0.0736,  0.9130,  1.0870, -1.5547,  2.0408,  0.6073,  0.2628],\n",
       "         [ 0.0107,  0.0736,  0.9130,  1.0870, -1.5547,  2.0408,  0.6073,  0.2628],\n",
       "         [ 0.0107,  0.0736,  0.9130,  1.0870, -1.5547,  2.0408,  0.6073,  0.2628],\n",
       "         [ 0.0107,  0.0736,  0.9130,  1.0870, -1.5547,  2.0408,  0.6073,  0.2628],\n",
       "         [ 0.0107,  0.0736,  0.9130,  1.0870, -1.5547,  2.0408,  0.6073,  0.2628],\n",
       "         [ 0.0107,  0.0736,  0.9130,  1.0870, -1.5547,  2.0408,  0.6073,  0.2628],\n",
       "         [ 0.0107,  0.0736,  0.9130,  1.0870, -1.5547,  2.0408,  0.6073,  0.2628],\n",
       "         [ 0.0107,  0.0736,  0.9130,  1.0870, -1.5547,  2.0408,  0.6073,  0.2628],\n",
       "         [ 0.0107,  0.0736,  0.9130,  1.0870, -1.5547,  2.0408,  0.6073,  0.2628],\n",
       "         [ 0.0107,  0.0736,  0.9130,  1.0870, -1.5547,  2.0408,  0.6073,  0.2628],\n",
       "         [ 0.0107,  0.0736,  0.9130,  1.0870, -1.5547,  2.0408,  0.6073,  0.2628],\n",
       "         [ 0.0107,  0.0736,  0.9130,  1.0870, -1.5547,  2.0408,  0.6073,  0.2628],\n",
       "         [ 0.0107,  0.0736,  0.9130,  1.0870, -1.5547,  2.0408,  0.6073,  0.2628],\n",
       "         [ 0.0107,  0.0736,  0.9130,  1.0870, -1.5547,  2.0408,  0.6073,  0.2628],\n",
       "         [ 0.0107,  0.0736,  0.9130,  1.0870, -1.5547,  2.0408,  0.6073,  0.2628],\n",
       "         [ 0.0107,  0.0736,  0.9130,  1.0870, -1.5547,  2.0408,  0.6073,  0.2628],\n",
       "         [ 0.0107,  0.0736,  0.9130,  1.0870, -1.5547,  2.0408,  0.6073,  0.2628],\n",
       "         [ 0.0107,  0.0736,  0.9130,  1.0870, -1.5547,  2.0408,  0.6073,  0.2628],\n",
       "         [ 0.0107,  0.0736,  0.9130,  1.0870, -1.5547,  2.0408,  0.6073,  0.2628],\n",
       "         [ 0.0107,  0.0736,  0.9130,  1.0870, -1.5547,  2.0408,  0.6073,  0.2628],\n",
       "         [ 0.0107,  0.0736,  0.9130,  1.0870, -1.5547,  2.0408,  0.6073,  0.2628],\n",
       "         [ 0.0107,  0.0736,  0.9130,  1.0870, -1.5547,  2.0408,  0.6073,  0.2628],\n",
       "         [ 0.0107,  0.0736,  0.9130,  1.0870, -1.5547,  2.0408,  0.6073,  0.2628],\n",
       "         [ 0.0107,  0.0736,  0.9130,  1.0870, -1.5547,  2.0408,  0.6073,  0.2628],\n",
       "         [ 0.0107,  0.0736,  0.9130,  1.0870, -1.5547,  2.0408,  0.6073,  0.2628],\n",
       "         [ 0.0107,  0.0736,  0.9130,  1.0870, -1.5547,  2.0408,  0.6073,  0.2628],\n",
       "         [ 0.0107,  0.0736,  0.9130,  1.0870, -1.5547,  2.0408,  0.6073,  0.2628],\n",
       "         [ 0.0107,  0.0736,  0.9130,  1.0870, -1.5547,  2.0408,  0.6073,  0.2628],\n",
       "         [ 0.0107,  0.0736,  0.9130,  1.0870, -1.5547,  2.0408,  0.6073,  0.2628]],\n",
       "        grad_fn=<CatBackward>),\n",
       " tensor([[ 1.4418, -1.8381, -0.6381, -0.3539, -0.3746, -0.9462, -0.0126, -0.1169],\n",
       "         [ 1.4418, -1.8381, -0.6381, -0.3539, -0.3746, -0.9462, -0.0126, -0.1169],\n",
       "         [ 1.4418, -1.8381, -0.6381, -0.3539, -0.3746, -0.9462, -0.0126, -0.1169],\n",
       "         [ 1.4418, -1.8381, -0.6381, -0.3539, -0.3746, -0.9462, -0.0126, -0.1169],\n",
       "         [ 1.4418, -1.8381, -0.6381, -0.3539, -0.3746, -0.9462, -0.0126, -0.1169],\n",
       "         [ 1.4418, -1.8381, -0.6381, -0.3539, -0.3746, -0.9462, -0.0126, -0.1169],\n",
       "         [ 1.4418, -1.8381, -0.6381, -0.3539, -0.3746, -0.9462, -0.0126, -0.1169],\n",
       "         [ 1.4418, -1.8381, -0.6381, -0.3539, -0.3746, -0.9462, -0.0126, -0.1169],\n",
       "         [ 1.4418, -1.8381, -0.6381, -0.3539, -0.3746, -0.9462, -0.0126, -0.1169],\n",
       "         [ 1.4418, -1.8381, -0.6381, -0.3539, -0.3746, -0.9462, -0.0126, -0.1169],\n",
       "         [ 1.4418, -1.8381, -0.6381, -0.3539, -0.3746, -0.9462, -0.0126, -0.1169],\n",
       "         [ 1.4418, -1.8381, -0.6381, -0.3539, -0.3746, -0.9462, -0.0126, -0.1169],\n",
       "         [ 1.4418, -1.8381, -0.6381, -0.3539, -0.3746, -0.9462, -0.0126, -0.1169],\n",
       "         [ 1.4418, -1.8381, -0.6381, -0.3539, -0.3746, -0.9462, -0.0126, -0.1169],\n",
       "         [ 1.4418, -1.8381, -0.6381, -0.3539, -0.3746, -0.9462, -0.0126, -0.1169],\n",
       "         [ 1.4418, -1.8381, -0.6381, -0.3539, -0.3746, -0.9462, -0.0126, -0.1169],\n",
       "         [ 1.4418, -1.8381, -0.6381, -0.3539, -0.3746, -0.9462, -0.0126, -0.1169],\n",
       "         [ 1.4418, -1.8381, -0.6381, -0.3539, -0.3746, -0.9462, -0.0126, -0.1169],\n",
       "         [ 1.4418, -1.8381, -0.6381, -0.3539, -0.3746, -0.9462, -0.0126, -0.1169],\n",
       "         [ 1.4418, -1.8381, -0.6381, -0.3539, -0.3746, -0.9462, -0.0126, -0.1169],\n",
       "         [ 1.4418, -1.8381, -0.6381, -0.3539, -0.3746, -0.9462, -0.0126, -0.1169],\n",
       "         [ 1.4418, -1.8381, -0.6381, -0.3539, -0.3746, -0.9462, -0.0126, -0.1169],\n",
       "         [ 1.4418, -1.8381, -0.6381, -0.3539, -0.3746, -0.9462, -0.0126, -0.1169],\n",
       "         [ 1.4418, -1.8381, -0.6381, -0.3539, -0.3746, -0.9462, -0.0126, -0.1169],\n",
       "         [ 1.4418, -1.8381, -0.6381, -0.3539, -0.3746, -0.9462, -0.0126, -0.1169],\n",
       "         [ 1.4418, -1.8381, -0.6381, -0.3539, -0.3746, -0.9462, -0.0126, -0.1169],\n",
       "         [ 1.4418, -1.8381, -0.6381, -0.3539, -0.3746, -0.9462, -0.0126, -0.1169],\n",
       "         [ 1.4418, -1.8381, -0.6381, -0.3539, -0.3746, -0.9462, -0.0126, -0.1169],\n",
       "         [ 1.4418, -1.8381, -0.6381, -0.3539, -0.3746, -0.9462, -0.0126, -0.1169],\n",
       "         [ 1.4418, -1.8381, -0.6381, -0.3539, -0.3746, -0.9462, -0.0126, -0.1169],\n",
       "         [ 1.4418, -1.8381, -0.6381, -0.3539, -0.3746, -0.9462, -0.0126, -0.1169],\n",
       "         [ 1.4418, -1.8381, -0.6381, -0.3539, -0.3746, -0.9462, -0.0126, -0.1169]],\n",
       "        grad_fn=<CatBackward>)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def condition_embedding(condition_size, batch_size=1, condition=None):\n",
    "    order = {'sp':0, 'tp':1, 'pg':2, 'p':3}\n",
    "    embedding = nn.Embedding(4, condition_size)\n",
    "    \n",
    "    if condition:\n",
    "        ondition_tensor = torch.tensor(order[condition])\n",
    "        embedded_tense = embedding(condition_tensor).view(1, -1)\n",
    "    else: \n",
    "        embedded_tense = []\n",
    "        for o in order.values():\n",
    "            condition_tensor = torch.tensor(o)\n",
    "            embedded = embedding(condition_tensor).view(1, -1)\n",
    "            embedded_cp = embedded\n",
    "            # expand batch dim, (4, condition_size) to (4, batch_size, condition_size)\n",
    "            for i in range(batch_size-1):\n",
    "                embedded = torch.cat((embedded, embedded_cp), 0)\n",
    "            embedded_tense.append(embedded)\n",
    "        \n",
    "    return embedded_tense\n",
    "                     \n",
    "condition_embedding(condition_size, 32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-11T03:14:20.083500Z",
     "start_time": "2020-05-11T03:14:20.080640Z"
    }
   },
   "outputs": [],
   "source": [
    "#compute BLEU-4 score\n",
    "def compute_bleu(output, reference):\n",
    "    \"\"\"\n",
    "    reference = 'accessed'\n",
    "    output = 'access'\n",
    "    return BLEU score\n",
    "    \"\"\"\n",
    "    cc = SmoothingFunction()\n",
    "    if len(reference) == 3:\n",
    "        weights = (0.33,0.33,0.33)\n",
    "    else:\n",
    "        weights = (0.25,0.25,0.25,0.25)\n",
    "    return sentence_bleu([reference], output,weights=weights,smoothing_function=cc.method1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-11T03:14:20.087921Z",
     "start_time": "2020-05-11T03:14:20.084472Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# compute generation score\n",
    "def Gaussian_score(predictions, plot_pred=False):\n",
    "    \"\"\"\n",
    "    the order should be : simple present, third person, present progressive, past\n",
    "    predictions = [['consult', 'consults', 'consulting', 'consulted'],...]\n",
    "    return Gaussian_score score\n",
    "    \"\"\"\n",
    "    score = 0\n",
    "    words_list = []\n",
    "    with open('./data/train.txt','r') as fp:\n",
    "        for line in fp:\n",
    "            word = line.split(' ')\n",
    "            word[3] = word[3].strip('\\n')\n",
    "            words_list.extend([word])\n",
    "        for idx, t in enumerate(predictions):\n",
    "            if plot_pred:\n",
    "                print (t)\n",
    "            for idxj, i in enumerate(words_list):\n",
    "                if t == i:\n",
    "                    score += 1\n",
    "    return score/len(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-11T03:14:20.096648Z",
     "start_time": "2020-05-11T03:14:20.088866Z"
    }
   },
   "outputs": [],
   "source": [
    "def predict(encoder, decoder, vocab, batch_size=64, plot_pred=False):\n",
    "#     # create dataloader\n",
    "#     trainset = TenseLoader('train', vocab)\n",
    "#     trainloader = data.DataLoader(trainset, batch_size=batch_size)\n",
    "        \n",
    "    prediction = []\n",
    "    inputs = []\n",
    "    outputs = []\n",
    "\n",
    "    with torch.no_grad():    \n",
    "#         for input_tensors in trainloader:  \n",
    "        for i in range(100):\n",
    "#             batch_size = input_tensors.size(0)\n",
    "            # get 4 tense embedding tensor\n",
    "            embedded_tenses = condition_embedding(condition_size , 1)\n",
    "            \n",
    "#             # transpose tensor from (batch_size, tense, seq_len) to (tense, seq_len, batch_size)\n",
    "#             input_tensors = input_tensors.to(device)\n",
    "#             input_tensors = input_tensors.permute(1, 2, 0)\n",
    "            # record outputs\n",
    "            output_tensors = torch.zeros(input_tensors.size())\n",
    "\n",
    "            # 4 tense iteration\n",
    "            for index, embedded_tense in enumerate(embedded_tenses):\n",
    "                # init hidden state and cat condition\n",
    "                encoder_hidden = encoder.initHidden(embedded_tense, batch_size)\n",
    "                \n",
    "                input_tensor = input_tensors[index] # (seq_len, batch_size)\n",
    "\n",
    "                # calculate number of time step\n",
    "                input_length = input_tensor.size(0)\n",
    "\n",
    "                #----------sequence to sequence part for encoder----------#\n",
    "                for ei in range(input_length):\n",
    "                    encoder_output, encoder_hidden = encoder(\n",
    "                        input_tensor[ei], encoder_hidden)\n",
    "\n",
    "                decoder_input = torch.tensor([[SOS_token] for i in range(batch_size)], device=device)\n",
    "                output = torch.zeros(input_length, batch_size)\n",
    "\n",
    "                # reparameterization trick\n",
    "                mu, logvar = encoder.variational(encoder_hidden)\n",
    "                reparameterized_state = reparameterize(mu, logvar)\n",
    "\n",
    "                # init decoder hidden state and cat condition\n",
    "                decoder_hidden = decoder.initHidden(reparameterized_state, embedded_tense, batch_size)\n",
    "\n",
    "                #----------sequence to sequence part for decoder----------#\n",
    "                for di in range(input_length):\n",
    "                    decoder_output, decoder_hidden = decoder(\n",
    "                        decoder_input, decoder_hidden) \n",
    "                    topv, topi = decoder_output.topk(1)\n",
    "                    decoder_input = topi.squeeze().detach()  # detach from history as input\n",
    "                    output[di] = decoder_input\n",
    "                \n",
    "                # get predict tensors\n",
    "                output_tensors[index] = output\n",
    "\n",
    "            # transpose tensor from (tense, seq_len, batch_size) to (batch_size, tense, seq_len)\n",
    "            output_tensors = output_tensors.permute(2, 0, 1)\n",
    "\n",
    "            # convert input into string\n",
    "            for idx in range(batch_size):\n",
    "                outputs.append([vocab.indices2word(tense.data.numpy()) for tense in output_tensors[idx]])\n",
    "\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-11T03:14:20.100394Z",
     "start_time": "2020-05-11T03:14:20.098123Z"
    }
   },
   "outputs": [],
   "source": [
    "# def test(encoder, decoder, vocab, plot_pred=False):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-11T03:14:20.104094Z",
     "start_time": "2020-05-11T03:14:20.101324Z"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate(encoder, decoder, vocab, batch_size=64, plot_pred=False):\n",
    "    # predict train.txt for gaussian score\n",
    "    predictions = predict(encoder, decoder, vocab, batch_size=batch_size, plot_pred=plot_pred)\n",
    "    \n",
    "    # compute Gaussian score\n",
    "    gaussian_score = Gaussian_score(predictions, plot_pred=plot_pred)\n",
    "    if plot_pred:\n",
    "        print (\"Gaussian score: %.2f\"%gaussian_score)\n",
    "\n",
    "    # predict test.txt for bleu score\n",
    "            \n",
    "    # compute BLEU score\n",
    "    \n",
    "    \n",
    "    return predictions, gaussian_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reparameterization Trick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-11T03:14:20.107324Z",
     "start_time": "2020-05-11T03:14:20.105084Z"
    }
   },
   "outputs": [],
   "source": [
    "def reparameterize(mu, logvar):\n",
    "    std = torch.exp(0.5*logvar)\n",
    "    eps = torch.randn_like(std)\n",
    "    return mu + eps*std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-11T03:14:20.114749Z",
     "start_time": "2020-05-11T03:14:20.108593Z"
    }
   },
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, laten_size, condition_size):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.condition_size = condition_size\n",
    "        \n",
    "        self.fc1 = nn.Linear(hidden_size+condition_size, laten_size)\n",
    "        self.fc2 = nn.Linear(hidden_size+condition_size, laten_size)\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size+condition_size)\n",
    "        self.lstm = nn.LSTM(hidden_size+condition_size, hidden_size+condition_size)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        embedded = self.embedding(input).view(1, -1, self.hidden_size+condition_size)\n",
    "        output = embedded\n",
    "        output, hidden = self.lstm(output, hidden)\n",
    "        return output, hidden\n",
    "    \n",
    "    def variational(self, hidden):\n",
    "        return self.fc1(hidden[0]), self.fc2(hidden[0])\n",
    "\n",
    "    def initHidden(self, embedded_tense, batch_size=64):\n",
    "        embedded_tense = embedded_tense.to(device).view(1, batch_size, -1)\n",
    "        zeros = torch.zeros(1, batch_size, self.hidden_size, device=device)\n",
    "        return (torch.cat((zeros, embedded_tense), 2),\n",
    "                torch.cat((zeros, embedded_tense), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-11T03:14:20.120892Z",
     "start_time": "2020-05-11T03:14:20.115783Z"
    }
   },
   "outputs": [],
   "source": [
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, condition_size):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.condition_size = condition_size\n",
    "\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size+condition_size)\n",
    "        self.lstm = nn.LSTM(hidden_size+condition_size, hidden_size+condition_size)\n",
    "        self.out = nn.Linear(hidden_size+condition_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        output = self.embedding(input).view(1, -1, self.hidden_size+condition_size)\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.lstm(output, hidden)\n",
    "        output = self.out(output[0])\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self, hidden_state, embedded_tense, batch_size):\n",
    "        embedded_tense = embedded_tense.to(device).view(1, batch_size, -1)\n",
    "        return (torch.cat((hidden_state, embedded_tense), 2),\n",
    "                torch.cat((hidden_state, embedded_tense), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train\n",
    "* Use teacher forcing\n",
    "* Use KL loss annealing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-11T03:14:20.124631Z",
     "start_time": "2020-05-11T03:14:20.121902Z"
    }
   },
   "outputs": [],
   "source": [
    "def kl_annealing(epochs, mode):\n",
    "    assert mode == \"monotonic\" or mode == \"cyclical\"\n",
    "    if mode == \"monotonic\":\n",
    "        if epochs > 1e4:\n",
    "            KLD_weight = 1\n",
    "        else:\n",
    "            KLD_weight = 1e-4 * epochs\n",
    "    else:\n",
    "        if epochs%1e4 > 5e3:\n",
    "            KLD_weight = 1\n",
    "        else:\n",
    "            KLD_weight = 2e-1 * epochs\n",
    "    return KLD_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-11T03:14:20.127771Z",
     "start_time": "2020-05-11T03:14:20.125649Z"
    }
   },
   "outputs": [],
   "source": [
    "def compute_kl_loss(mu, logvar):\n",
    "    # 0.5 * sum(1 + log(sigma^2) - mu^2 - sigma^2)\n",
    "    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "    return KLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-11T03:14:20.135919Z",
     "start_time": "2020-05-11T03:14:20.128663Z"
    }
   },
   "outputs": [],
   "source": [
    "# save model every epoch\n",
    "def train(input_tensors, encoder, decoder, encoder_optimizer, decoder_optimizer, \n",
    "          criterion, epochs, teacher_forcing_ratio):\n",
    "    batch_size = input_tensors.size(0)\n",
    "    # get 4 tense embedding tensor\n",
    "    embedded_tenses = condition_embedding(condition_size, batch_size)\n",
    "    \n",
    "    # loss for 4 tense\n",
    "    kl_loss_total = 0\n",
    "    ce_loss_total = 0\n",
    "    \n",
    "    # transpose tensor from (batch_size, tense, seq_len) to (tense, seq_len, batch_size)\n",
    "    input_tensors = input_tensors.permute(1, 2, 0)\n",
    "    \n",
    "    # 4 tense iteration\n",
    "    for index, embedded_tense in enumerate(embedded_tenses):\n",
    "        # embedded_tense.to(device)\n",
    "        input_tensor = input_tensors[index] # (seq_len, batch_size)\n",
    "    \n",
    "        # init encoder hidden state and cat condition\n",
    "        encoder_hidden = encoder.initHidden(embedded_tense, batch_size)\n",
    "\n",
    "        encoder_optimizer.zero_grad()\n",
    "        decoder_optimizer.zero_grad()\n",
    "\n",
    "        # calculate number of time step\n",
    "        input_length = input_tensor.size(0)\n",
    "\n",
    "        loss = 0\n",
    "        ce_loss = 0\n",
    "\n",
    "        #----------sequence to sequence part for encoder----------#\n",
    "        for ei in range(input_length):\n",
    "            encoder_output, encoder_hidden = encoder(\n",
    "                input_tensor[ei], encoder_hidden)\n",
    "            \n",
    "        # reparameterization trick\n",
    "        mu, logvar = encoder.variational(encoder_hidden)\n",
    "        reparameterized_state = reparameterize(mu, logvar)\n",
    "        \n",
    "        # calculate kl loss\n",
    "        kl_loss = compute_kl_loss(mu, logvar)\n",
    "        kl_loss_total += kl_annealing(epochs, \"monotonic\") * kl_loss\n",
    "        loss += kl_annealing(epochs, \"monotonic\") * kl_loss\n",
    "\n",
    "        # init decoder hidden state and cat condition\n",
    "        decoder_hidden = decoder.initHidden(reparameterized_state, embedded_tense, batch_size)\n",
    "        \n",
    "        decoder_input = torch.tensor([[SOS_token] for i in range(batch_size)], device=device)\n",
    "\n",
    "        use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "\n",
    "        #----------sequence to sequence part for decoder----------#\n",
    "        if use_teacher_forcing:\n",
    "            # Teacher forcing: Feed the target as the next input\n",
    "            for di in range(input_length):\n",
    "                decoder_output, decoder_hidden = decoder(\n",
    "                    decoder_input, decoder_hidden) \n",
    "                ce_loss += criterion(decoder_output, input_tensor[di])\n",
    "                decoder_input = input_tensor[di]  # Teacher forcing\n",
    "\n",
    "        else:\n",
    "            # Without teacher forcing: use its own predictions as the next input\n",
    "            for di in range(input_length):\n",
    "                decoder_output, decoder_hidden = decoder(\n",
    "                    decoder_input, decoder_hidden) \n",
    "                topv, topi = decoder_output.topk(1)\n",
    "                decoder_input = topi.squeeze().detach()  # detach from history as input\n",
    "\n",
    "                ce_loss += criterion(decoder_output, input_tensor[di])\n",
    "\n",
    "        loss += ce_loss\n",
    "        ce_loss_total += (ce_loss.item()/input_length)\n",
    "        loss.backward()\n",
    "\n",
    "        encoder_optimizer.step()\n",
    "        decoder_optimizer.step()\n",
    "\n",
    "    return ce_loss_total/4, kl_loss_total/4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-11T03:14:20.143870Z",
     "start_time": "2020-05-11T03:14:20.137612Z"
    }
   },
   "outputs": [],
   "source": [
    "def trainIters(encoder, decoder, vocab, n_iters, print_every=1000, plot_every=100, \n",
    "               batch_size=64, learning_rate=0.01, teacher_forcing_ratio=1.0):\n",
    "    start = time.time()\n",
    "\n",
    "    # Reset every print_every, for print log\n",
    "    print_ce_loss_total = 0  \n",
    "    print_kl_loss_total = 0\n",
    "    # Reset every plot_every, for plot curve\n",
    "    crossentropy_losses = []\n",
    "    kl_losses = []\n",
    "    plot_ce_loss_total = 0\n",
    "    plot_kl_loss_total = 0\n",
    "    # scores\n",
    "    gaussian_scores = []\n",
    "    bleu_scores = []\n",
    "    \n",
    "\n",
    "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
    "\n",
    "    # create dataloader\n",
    "    trainset = TenseLoader('train', vocab)\n",
    "    trainloader = data.DataLoader(trainset, batch_size, shuffle = True)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    for iter in range(1, n_iters + 1):\n",
    "        for input_tensors in trainloader:\n",
    "            input_tensors = input_tensors.to(device)\n",
    "\n",
    "            ce_loss, kl_loss = train(input_tensors, encoder, decoder, encoder_optimizer, decoder_optimizer, \n",
    "                                     criterion, (iter-1), teacher_forcing_ratio)\n",
    "            print_ce_loss_total += ce_loss\n",
    "            print_kl_loss_total += kl_loss\n",
    "            plot_ce_loss_total += ce_loss\n",
    "            plot_kl_loss_total += kl_loss\n",
    "            \n",
    "        # evaluate and save model\n",
    "        _, gaussian_score = evaluate(encoder, decoder, vocab, plot_pred=False)\n",
    "        gaussian_scores.append(gaussian_score)\n",
    "        if (iter-1) > 500:\n",
    "#             max_score = avg_bleu\n",
    "            print (\"Model save...\")\n",
    "            torch.save(encoder, \"./models/encoder_{}.ckpt\".format((iter-1)))\n",
    "            torch.save(decoder, \"./models/decoder_{}.ckpt\".format((iter-1)))\n",
    "\n",
    "        if iter % print_every == 0:\n",
    "            print_ce_loss_avg = print_ce_loss_total / print_every\n",
    "            print_kl_loss_avg = print_kl_loss_total / print_every\n",
    "            print('%s (%d %2d%%) CE Loss: %.4f, KL Loss: %.4f, Gaussian score: %.2f' % \n",
    "                  (timeSince(start, iter / n_iters), iter, iter / n_iters * 100, print_ce_loss_avg, print_kl_loss_avg, gaussian_score))\n",
    "            print_ce_loss_total = 0\n",
    "            print_kl_loss_total = 0\n",
    "\n",
    "        crossentropy_losses.append(plot_ce_loss_total)\n",
    "        plot_ce_loss_total = 0\n",
    "        kl_losses.append(plot_kl_loss_total)\n",
    "        plot_kl_loss_total = 0\n",
    "            \n",
    "#     print (\"The highest score is %s\"%max_score)\n",
    "            \n",
    "    return gaussian_scores, crossentropy_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-05-11T03:14:18.278Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3m 51s (- 34m 41s) (100 10%) CE Loss: 19.9754, KL Loss: 0.1189, Gaussian score: 0.00\n",
      "7m 49s (- 31m 16s) (200 20%) CE Loss: 13.4573, KL Loss: 0.0200, Gaussian score: 0.00\n",
      "11m 47s (- 27m 30s) (300 30%) CE Loss: 12.0685, KL Loss: 0.0130, Gaussian score: 0.00\n",
      "15m 51s (- 23m 46s) (400 40%) CE Loss: 11.7996, KL Loss: 0.0102, Gaussian score: 0.00\n",
      "19m 56s (- 19m 56s) (500 50%) CE Loss: 11.6990, KL Loss: 0.0089, Gaussian score: 0.00\n",
      "24m  3s (- 16m  2s) (600 60%) CE Loss: 11.6481, KL Loss: 0.0081, Gaussian score: 0.00\n",
      "28m  6s (- 12m  2s) (700 70%) CE Loss: 11.6116, KL Loss: 0.0073, Gaussian score: 0.00\n",
      "32m  7s (- 8m  1s) (800 80%) CE Loss: 11.5874, KL Loss: 0.0066, Gaussian score: 0.00\n"
     ]
    }
   ],
   "source": [
    "encoder1 = EncoderRNN(vocab_size, hidden_size, laten_size, condition_size).to(device)\n",
    "decoder1 = DecoderRNN(laten_size, vocab_size, condition_size).to(device)\n",
    "vocab = Vocabuary()\n",
    "gaussian_scores, crossentropy_losses = trainIters(encoder1, decoder1, vocab, 1000, print_every=100, plot_every=1, teacher_forcing_ratio=1)\n",
    "# show_result(scores, losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-05-11T03:14:18.279Z"
    }
   },
   "outputs": [],
   "source": [
    "pred,_  = evaluate(encoder1, decoder1, vocab, batch_size=64, plot_pred=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
